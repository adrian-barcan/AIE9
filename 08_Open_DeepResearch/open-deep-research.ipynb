{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangGraph Open Deep Research - Supervisor-Researcher Architecture\n",
    "\n",
    "In this notebook, we'll explore the **supervisor-researcher delegation architecture** for conducting deep research with LangGraph.\n",
    "\n",
    "You can visit this repository to see the original application: [Open Deep Research](https://github.com/langchain-ai/open_deep_research)\n",
    "\n",
    "Let's jump in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What We're Building\n",
    "\n",
    "This implementation uses a **hierarchical delegation pattern** where:\n",
    "\n",
    "1. **User Clarification** - Optionally asks clarifying questions to understand the research scope\n",
    "2. **Research Brief Generation** - Transforms user messages into a structured research brief\n",
    "3. **Supervisor** - A lead researcher that analyzes the brief and delegates research tasks\n",
    "4. **Parallel Researchers** - Multiple sub-agents that conduct focused research simultaneously\n",
    "5. **Research Compression** - Each researcher synthesizes their findings\n",
    "6. **Final Report** - All findings are combined into a comprehensive report\n",
    "\n",
    "![Architecture Diagram](https://i.imgur.com/Q8HEZn0.png)\n",
    "\n",
    "This differs from a section-based approach by allowing dynamic task decomposition based on the research question, rather than predefined sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ü§ù Breakout Room #1\n",
    "## Deep Research Foundations\n",
    "\n",
    "In this breakout room, we'll understand the architecture and components of the Open Deep Research system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Dependencies\n",
    "\n",
    "You'll need API keys for Anthropic (for the LLM) and Tavily (for web search). We'll configure the system to use Anthropic's Claude Sonnet 4 exclusively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: State Definitions\n",
    "\n",
    "The state structure is hierarchical with three levels:\n",
    "\n",
    "### Agent State (Top Level)\n",
    "Contains the overall conversation messages, research brief, accumulated notes, and final report.\n",
    "\n",
    "### Supervisor State (Middle Level)\n",
    "Manages the research supervisor's messages, research iterations, and coordinating parallel researchers.\n",
    "\n",
    "### Researcher State (Bottom Level)\n",
    "Each individual researcher has their own message history, tool call iterations, and research findings.\n",
    "\n",
    "We also have structured outputs for tool calling:\n",
    "- **ConductResearch** - Tool for supervisor to delegate research to a sub-agent\n",
    "- **ResearchComplete** - Tool to signal research phase is done\n",
    "- **ClarifyWithUser** - Structured output for asking clarifying questions\n",
    "- **ResearchQuestion** - Structured output for the research brief\n",
    "\n",
    "Let's import these from our library: [`open_deep_library/state.py`](open_deep_library/state.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import state definitions from the library\n",
    "from open_deep_library.state import (\n",
    "    # Main workflow states\n",
    "    AgentState,           # Lines 65-72: Top-level agent state with messages, research_brief, notes, final_report\n",
    "    AgentInputState,      # Lines 62-63: Input state is just messages\n",
    "    \n",
    "    # Supervisor states\n",
    "    SupervisorState,      # Lines 74-81: Supervisor manages research delegation and iterations\n",
    "    \n",
    "    # Researcher states\n",
    "    ResearcherState,      # Lines 83-90: Individual researcher with messages and tool iterations\n",
    "    ResearcherOutputState, # Lines 92-96: Output from researcher (compressed research + raw notes)\n",
    "    \n",
    "    # Structured outputs for tool calling\n",
    "    ConductResearch,      # Lines 15-19: Tool for delegating research to sub-agents\n",
    "    ResearchComplete,     # Lines 21-22: Tool to signal research completion\n",
    "    ClarifyWithUser,      # Lines 30-41: Structured output for user clarification\n",
    "    ResearchQuestion,     # Lines 43-48: Structured output for research brief\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Utility Functions and Tools\n",
    "\n",
    "The system uses several key utilities:\n",
    "\n",
    "### Search Tools\n",
    "- **tavily_search** - Async web search with automatic summarization to stay within token limits\n",
    "- Supports Anthropic native web search and Tavily API\n",
    "\n",
    "### Reflection Tools\n",
    "- **think_tool** - Allows researchers to reflect on their progress and plan next steps (ReAct pattern)\n",
    "\n",
    "### Helper Utilities\n",
    "- **get_all_tools** - Assembles the complete toolkit (search + MCP + reflection)\n",
    "- **get_today_str** - Provides current date context for research\n",
    "- Token limit handling utilities for graceful degradation\n",
    "\n",
    "These are defined in [`open_deep_library/utils.py`](open_deep_library/utils.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import utility functions and tools from the library\n",
    "from open_deep_library.utils import (\n",
    "    # Search tool - Lines 43-136: Tavily search with automatic summarization\n",
    "    tavily_search,\n",
    "    \n",
    "    # Reflection tool - Lines 219-244: Strategic thinking tool for ReAct pattern\n",
    "    think_tool,\n",
    "    \n",
    "    # Tool assembly - Lines 569-597: Get all configured tools\n",
    "    get_all_tools,\n",
    "    \n",
    "    # Date utility - Lines 872-879: Get formatted current date\n",
    "    get_today_str,\n",
    "    \n",
    "    # Supporting utilities for error handling\n",
    "    get_api_key_for_model,          # Lines 892-914: Get API keys from config or env\n",
    "    is_token_limit_exceeded,         # Lines 665-701: Detect token limit errors\n",
    "    get_model_token_limit,           # Lines 831-846: Look up model's token limit\n",
    "    remove_up_to_last_ai_message,    # Lines 848-866: Truncate messages for retry\n",
    "    anthropic_websearch_called,      # Lines 607-637: Detect Anthropic native search usage\n",
    "    openai_websearch_called,         # Lines 639-658: Detect OpenAI native search usage\n",
    "    get_notes_from_tool_calls,       # Lines 599-601: Extract notes from tool messages\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Configuration System\n",
    "\n",
    "The configuration system controls:\n",
    "\n",
    "### Research Behavior\n",
    "- **allow_clarification** - Whether to ask clarifying questions before research\n",
    "- **max_concurrent_research_units** - How many parallel researchers can run (default: 5)\n",
    "- **max_researcher_iterations** - How many times supervisor can delegate research (default: 6)\n",
    "- **max_react_tool_calls** - Tool call limit per researcher (default: 10)\n",
    "\n",
    "### Model Configuration\n",
    "- **research_model** - Model for research and supervision (we'll use Anthropic)\n",
    "- **compression_model** - Model for synthesizing findings\n",
    "- **final_report_model** - Model for writing the final report\n",
    "- **summarization_model** - Model for summarizing web search results\n",
    "\n",
    "### Search Configuration\n",
    "- **search_api** - Which search API to use (ANTHROPIC, TAVILY, or NONE)\n",
    "- **max_content_length** - Character limit before summarization\n",
    "\n",
    "Defined in [`open_deep_library/configuration.py`](open_deep_library/configuration.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import configuration from the library\n",
    "from open_deep_library.configuration import (\n",
    "    Configuration,    # Lines 38-247: Main configuration class with all settings\n",
    "    SearchAPI,        # Lines 11-17: Enum for search API options (ANTHROPIC, TAVILY, NONE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Prompt Templates\n",
    "\n",
    "The system uses carefully engineered prompts for each phase:\n",
    "\n",
    "### Phase 1: Clarification\n",
    "**clarify_with_user_instructions** - Analyzes if the research scope is clear or needs clarification\n",
    "\n",
    "### Phase 2: Research Brief\n",
    "**transform_messages_into_research_topic_prompt** - Converts user messages into a detailed research brief\n",
    "\n",
    "### Phase 3: Supervisor\n",
    "**lead_researcher_prompt** - System prompt for the supervisor that manages delegation strategy\n",
    "\n",
    "### Phase 4: Researcher\n",
    "**research_system_prompt** - System prompt for individual researchers conducting focused research\n",
    "\n",
    "### Phase 5: Compression\n",
    "**compress_research_system_prompt** - Prompt for synthesizing research findings without losing information\n",
    "\n",
    "### Phase 6: Final Report\n",
    "**final_report_generation_prompt** - Comprehensive prompt for writing the final report\n",
    "\n",
    "All prompts are defined in [`open_deep_library/prompts.py`](open_deep_library/prompts.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import prompt templates from the library\n",
    "from open_deep_library.prompts import (\n",
    "    clarify_with_user_instructions,                    # Lines 3-41: Ask clarifying questions\n",
    "    transform_messages_into_research_topic_prompt,     # Lines 44-77: Generate research brief\n",
    "    lead_researcher_prompt,                            # Lines 79-136: Supervisor system prompt\n",
    "    research_system_prompt,                            # Lines 138-183: Researcher system prompt\n",
    "    compress_research_system_prompt,                   # Lines 186-222: Research compression prompt\n",
    "    final_report_generation_prompt,                    # Lines 228-308: Final report generation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùì Question #1:\n",
    "\n",
    "Explain the interrelationships between the three states (Agent, Supervisor, Researcher). Why don't we just make a single huge state?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer:\n",
    "\n",
    "The interrelationship is hierarchical:\n",
    "- Agent State (Top Level): Holds the global context (user interaction, research brief, final report) and orchestrates the overall workflow\n",
    "- Supervisor State (Middle Level): Manages the delegation strategy. It receives the brief from the Agent State and spawns multiple Researchers\n",
    "- Researcher State (Bottom Level): Independent, isolated states for each parallel subagent to conduct specific research and tool usage\n",
    "\n",
    "Why not a single huge state?\n",
    "- Context Window / Token Limits: A single state would accumulate every raw search result, tool output, and thought from every researcher. This would rapidly exceed the model's context window. Separate states allow researchers to do their detailed work, compress the results, and pass only the summary back up the chain\n",
    "- Parallelism: Independent states allow multiple researchers to run simultaneously without their message histories collide or confusing the model with irrelevant context from other active researchers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùì Question #2:\n",
    "\n",
    "What are the advantages and disadvantages of importing these components instead of including them in the notebook?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer:\n",
    "Advantages:\n",
    "- Keeps the notebook clean: By moving the heavy lifting (like the state definitions and graph construction) into external files, the notebook itself is much easier to read and focus on the high-level workflow. It doesn't get cluttered with hundreds of lines of implementation code\n",
    "- Reusability: It feels more like real software project. If I wanted to build a script or an app using this researcher later, I could just import open_deep_library instead of having to copy-paste giant code cells from a notebook\n",
    "\n",
    "Disadvantages:\n",
    "- Harder to learn the details: To understand exactly how something like the supervisor node works, I have to constantly context-switch and open the .py files instead of just scrolling up to see the code definition right there in a cell\n",
    "- Slower experimentation: If I want to tweak a prompt or change a tool's logic to see what happens, I can't just edit a cell and hit run. I have to edit the file, save it, and often restart the kernel to get the changes to reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Activity #1: Explore the Prompts\n",
    "\n",
    "Open `open_deep_library/prompts.py` and examine one of the prompt templates in detail.\n",
    "\n",
    "**Requirements:**\n",
    "1. Choose one prompt template (clarify, brief, supervisor, researcher, compression, or final report)\n",
    "2. Explain what the prompt is designed to accomplish\n",
    "3. Identify 2-3 key techniques used in the prompt (e.g., structured output, role definition, examples)\n",
    "4. Suggest one improvement you might make to the prompt\n",
    "\n",
    "**YOUR CODE HERE** - Write your analysis in a markdown cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have analyzed the lead_researcher_prompt (lines 79-136).\n",
    "\n",
    "1. Selected Prompt\n",
    "lead_researcher_prompt (The Supervisor)\n",
    "\n",
    "2. What it is designed to accomplish\n",
    "This prompt orchestrates the \"brain\" of the operation. Instead of trying to answer the question directly, it acts as a manager with the following goals:\n",
    "\n",
    "- Analyze the complexity of the user's request\n",
    "- Decompose the problem into parallelizable chunks (if necessary)\n",
    "- Delegate specific research tasks to sub-agents via the ConductResearch tool\n",
    "- Aggregate results and decide when sufficient information has been found to stop\n",
    "\n",
    "3. Key techniques used\n",
    "- Role prompting: It explicitly defines the persona: \"Think like a research manager with limited time and resources.\" This discourages the model from going down rabbit holes and encourages efficiency.\n",
    "- Explicit Constraints: It sets firm boundaries to prevent infinite loops and token waste, such as \"Limit tool calls... always stop after {max_researcher_iterations}\" and \"Bias towards single agent\"\n",
    "- Sequential Reasoning (CoT Enforcement): It forces a \"Think, then Act\" workflow by mandating the use of the think_tool before delegating and after receiving results. This forces the model to generate a chain-of-thought trace in the context window before committing to an action\n",
    "\n",
    "4. Suggested Improvement\n",
    "Add a \"Cross-Check\" step. Currently, the supervisor delegates tasks and then checks if it has \"enough\" info. It might be beneficial to explicitly instruct the supervisor to check for conflicting information between sub-agents. We can add a step in the <Show Your Thinking> section: \"If multiple researchers return conflicting data (e.g., different dates for the same event), explicitly formulate a new query to resolve the conflict before marking research as complete.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ü§ù Breakout Room #2\n",
    "## Building & Running the Researcher\n",
    "\n",
    "In this breakout room, we'll explore the node functions, build the graph, and run wellness research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Node Functions - The Building Blocks\n",
    "\n",
    "Now let's look at the node functions that make up our graph. We'll import them from the library and understand what each does.\n",
    "\n",
    "### The Complete Research Workflow\n",
    "\n",
    "The workflow consists of 8 key nodes organized into 3 subgraphs:\n",
    "\n",
    "1. **Main Graph Nodes:**\n",
    "   - `clarify_with_user` - Entry point that checks if clarification is needed\n",
    "   - `write_research_brief` - Transforms user input into structured research brief\n",
    "   - `final_report_generation` - Synthesizes all research into final report\n",
    "\n",
    "2. **Supervisor Subgraph Nodes:**\n",
    "   - `supervisor` - Lead researcher that plans and delegates\n",
    "   - `supervisor_tools` - Executes supervisor's tool calls (delegation, reflection)\n",
    "\n",
    "3. **Researcher Subgraph Nodes:**\n",
    "   - `researcher` - Individual researcher conducting focused research\n",
    "   - `researcher_tools` - Executes researcher's tool calls (search, reflection)\n",
    "   - `compress_research` - Synthesizes researcher's findings\n",
    "\n",
    "All nodes are defined in [`open_deep_library/deep_researcher.py`](open_deep_library/deep_researcher.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node 1: clarify_with_user\n",
    "\n",
    "**Purpose:** Analyzes user messages and asks clarifying questions if the research scope is unclear.\n",
    "\n",
    "**Key Steps:**\n",
    "1. Check if clarification is enabled in configuration\n",
    "2. Use structured output to analyze if clarification is needed\n",
    "3. If needed, end with a clarifying question for the user\n",
    "4. If not needed, proceed to research brief with verification message\n",
    "\n",
    "**Implementation:** [`open_deep_library/deep_researcher.py` lines 60-115](open_deep_library/deep_researcher.py#L60-L115)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the clarify_with_user node\n",
    "from open_deep_library.deep_researcher import clarify_with_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node 2: write_research_brief\n",
    "\n",
    "**Purpose:** Transforms user messages into a structured research brief for the supervisor.\n",
    "\n",
    "**Key Steps:**\n",
    "1. Use structured output to generate detailed research brief from messages\n",
    "2. Initialize supervisor with system prompt and research brief\n",
    "3. Set up supervisor messages with proper context\n",
    "\n",
    "**Why this matters:** A well-structured research brief helps the supervisor make better delegation decisions.\n",
    "\n",
    "**Implementation:** [`open_deep_library/deep_researcher.py` lines 118-175](open_deep_library/deep_researcher.py#L118-L175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the write_research_brief node\n",
    "from open_deep_library.deep_researcher import write_research_brief"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node 3: supervisor\n",
    "\n",
    "**Purpose:** Lead research supervisor that plans research strategy and delegates to sub-researchers.\n",
    "\n",
    "**Key Steps:**\n",
    "1. Configure model with three tools:\n",
    "   - `ConductResearch` - Delegate research to a sub-agent\n",
    "   - `ResearchComplete` - Signal that research is done\n",
    "   - `think_tool` - Strategic reflection before decisions\n",
    "2. Generate response based on current context\n",
    "3. Increment research iteration count\n",
    "4. Proceed to tool execution\n",
    "\n",
    "**Decision Making:** The supervisor uses `think_tool` to reflect before delegating research, ensuring thoughtful decomposition of the research question.\n",
    "\n",
    "**Implementation:** [`open_deep_library/deep_researcher.py` lines 178-223](open_deep_library/deep_researcher.py#L178-L223)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the supervisor node (from supervisor subgraph)\n",
    "from open_deep_library.deep_researcher import supervisor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node 4: supervisor_tools\n",
    "\n",
    "**Purpose:** Executes the supervisor's tool calls, including strategic thinking and research delegation.\n",
    "\n",
    "**Key Steps:**\n",
    "1. Check exit conditions:\n",
    "   - Exceeded maximum iterations\n",
    "   - No tool calls made\n",
    "   - `ResearchComplete` called\n",
    "2. Process `think_tool` calls for strategic reflection\n",
    "3. Execute `ConductResearch` calls in parallel:\n",
    "   - Spawn researcher subgraphs for each delegation\n",
    "   - Limit to `max_concurrent_research_units` (default: 5)\n",
    "   - Gather all results asynchronously\n",
    "4. Aggregate findings and return to supervisor\n",
    "\n",
    "**Parallel Execution:** This is where the magic happens - multiple researchers work simultaneously on different aspects of the research question.\n",
    "\n",
    "**Implementation:** [`open_deep_library/deep_researcher.py` lines 225-349](open_deep_library/deep_researcher.py#L225-L349)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the supervisor_tools node\n",
    "from open_deep_library.deep_researcher import supervisor_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node 5: researcher\n",
    "\n",
    "**Purpose:** Individual researcher that conducts focused research on a specific topic.\n",
    "\n",
    "**Key Steps:**\n",
    "1. Load all available tools (search, MCP, reflection)\n",
    "2. Configure model with tools and researcher system prompt\n",
    "3. Generate response with tool calls\n",
    "4. Increment tool call iteration count\n",
    "\n",
    "**ReAct Pattern:** Researchers use `think_tool` to reflect after each search, deciding whether to continue or provide their answer.\n",
    "\n",
    "**Available Tools:**\n",
    "- Search tools (Tavily or Anthropic native search)\n",
    "- `think_tool` for strategic reflection\n",
    "- `ResearchComplete` to signal completion\n",
    "- MCP tools (if configured)\n",
    "\n",
    "**Implementation:** [`open_deep_library/deep_researcher.py` lines 365-424](open_deep_library/deep_researcher.py#L365-L424)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the researcher node (from researcher subgraph)\n",
    "from open_deep_library.deep_researcher import researcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node 6: researcher_tools\n",
    "\n",
    "**Purpose:** Executes the researcher's tool calls, including searches and strategic reflection.\n",
    "\n",
    "**Key Steps:**\n",
    "1. Check early exit conditions (no tool calls, native search used)\n",
    "2. Execute all tool calls in parallel:\n",
    "   - Search tools fetch and summarize web content\n",
    "   - `think_tool` records strategic reflections\n",
    "   - MCP tools execute external integrations\n",
    "3. Check late exit conditions:\n",
    "   - Exceeded `max_react_tool_calls` (default: 10)\n",
    "   - `ResearchComplete` called\n",
    "4. Continue research loop or proceed to compression\n",
    "\n",
    "**Error Handling:** Safely handles tool execution errors and continues with available results.\n",
    "\n",
    "**Implementation:** [`open_deep_library/deep_researcher.py` lines 435-509](open_deep_library/deep_researcher.py#L435-L509)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the researcher_tools node\n",
    "from open_deep_library.deep_researcher import researcher_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node 7: compress_research\n",
    "\n",
    "**Purpose:** Compresses and synthesizes research findings into a concise, structured summary.\n",
    "\n",
    "**Key Steps:**\n",
    "1. Configure compression model\n",
    "2. Add compression instruction to messages\n",
    "3. Attempt compression with retry logic:\n",
    "   - If token limit exceeded, remove older messages\n",
    "   - Retry up to 3 times\n",
    "4. Extract raw notes from tool and AI messages\n",
    "5. Return compressed research and raw notes\n",
    "\n",
    "**Why Compression?** Researchers may accumulate lots of tool outputs and reflections. Compression ensures:\n",
    "- All important information is preserved\n",
    "- Redundant information is deduplicated\n",
    "- Content stays within token limits for the final report\n",
    "\n",
    "**Token Limit Handling:** Gracefully handles token limit errors by progressively truncating messages.\n",
    "\n",
    "**Implementation:** [`open_deep_library/deep_researcher.py` lines 511-585](open_deep_library/deep_researcher.py#L511-L585)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the compress_research node\n",
    "from open_deep_library.deep_researcher import compress_research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node 8: final_report_generation\n",
    "\n",
    "**Purpose:** Generates the final comprehensive research report from all collected findings.\n",
    "\n",
    "**Key Steps:**\n",
    "1. Extract all notes from completed research\n",
    "2. Configure final report model\n",
    "3. Attempt report generation with retry logic:\n",
    "   - If token limit exceeded, truncate findings by 10%\n",
    "   - Retry up to 3 times\n",
    "4. Return final report or error message\n",
    "\n",
    "**Token Limit Strategy:**\n",
    "- First retry: Use model's token limit √ó 4 as character limit\n",
    "- Subsequent retries: Reduce by 10% each time\n",
    "- Graceful degradation with helpful error messages\n",
    "\n",
    "**Report Quality:** The prompt guides the model to create well-structured reports with:\n",
    "- Proper headings and sections\n",
    "- Inline citations\n",
    "- Comprehensive coverage of all findings\n",
    "- Sources section at the end\n",
    "\n",
    "**Implementation:** [`open_deep_library/deep_researcher.py` lines 607-697](open_deep_library/deep_researcher.py#L607-L697)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the final_report_generation node\n",
    "from open_deep_library.deep_researcher import final_report_generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Graph Construction - Putting It All Together\n",
    "\n",
    "The system is organized into three interconnected graphs:\n",
    "\n",
    "### 1. Researcher Subgraph (Bottom Level)\n",
    "Handles individual focused research on a specific topic:\n",
    "```\n",
    "START ‚Üí researcher ‚Üí researcher_tools ‚Üí compress_research ‚Üí END\n",
    "               ‚Üë            ‚Üì\n",
    "               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò (loops until max iterations or ResearchComplete)\n",
    "```\n",
    "\n",
    "### 2. Supervisor Subgraph (Middle Level)\n",
    "Manages research delegation and coordination:\n",
    "```\n",
    "START ‚Üí supervisor ‚Üí supervisor_tools ‚Üí END\n",
    "            ‚Üë              ‚Üì\n",
    "            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò (loops until max iterations or ResearchComplete)\n",
    "            \n",
    "supervisor_tools spawns multiple researcher_subgraphs in parallel\n",
    "```\n",
    "\n",
    "### 3. Main Deep Researcher Graph (Top Level)\n",
    "Orchestrates the complete research workflow:\n",
    "```\n",
    "START ‚Üí clarify_with_user ‚Üí write_research_brief ‚Üí research_supervisor ‚Üí final_report_generation ‚Üí END\n",
    "                 ‚Üì                                       (supervisor_subgraph)\n",
    "               (may end early if clarification needed)\n",
    "```\n",
    "\n",
    "Let's import the compiled graphs from the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pre-compiled graphs from the library\n",
    "from open_deep_library.deep_researcher import (\n",
    "    # Bottom level: Individual researcher workflow\n",
    "    researcher_subgraph,    # Lines 588-605: researcher ‚Üí researcher_tools ‚Üí compress_research\n",
    "    \n",
    "    # Middle level: Supervisor coordination\n",
    "    supervisor_subgraph,    # Lines 351-363: supervisor ‚Üí supervisor_tools (spawns researchers)\n",
    "    \n",
    "    # Top level: Complete research workflow\n",
    "    deep_researcher,        # Lines 699-719: Main graph with all phases\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why This Architecture?\n",
    "\n",
    "### Advantages of Supervisor-Researcher Delegation\n",
    "\n",
    "1. **Dynamic Task Decomposition**\n",
    "   - Unlike section-based approaches with predefined structure, the supervisor can break down research based on the actual question\n",
    "   - Adapts to different types of research (comparisons, lists, deep dives, etc.)\n",
    "\n",
    "2. **Parallel Execution**\n",
    "   - Multiple researchers work simultaneously on different aspects\n",
    "   - Much faster than sequential section processing\n",
    "   - Configurable parallelism (1-20 concurrent researchers)\n",
    "\n",
    "3. **ReAct Pattern for Quality**\n",
    "   - Researchers use `think_tool` to reflect after each search\n",
    "   - Prevents excessive searching and improves search quality\n",
    "   - Natural stopping conditions based on information sufficiency\n",
    "\n",
    "4. **Flexible Tool Integration**\n",
    "   - Easy to add MCP tools for specialized research\n",
    "   - Supports multiple search APIs (Anthropic, Tavily)\n",
    "   - Each researcher can use different tool combinations\n",
    "\n",
    "5. **Graceful Token Limit Handling**\n",
    "   - Compression prevents token overflow\n",
    "   - Progressive truncation in final report generation\n",
    "   - Research can scale to arbitrary depths\n",
    "\n",
    "### Trade-offs\n",
    "\n",
    "- **Complexity:** More moving parts than section-based approach\n",
    "- **Cost:** Parallel researchers use more tokens (but faster)\n",
    "- **Unpredictability:** Research structure emerges dynamically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Running the Deep Researcher\n",
    "\n",
    "Now let's see the system in action! We'll use it to research wellness strategies for improving sleep quality.\n",
    "\n",
    "### Setup\n",
    "\n",
    "We need to:\n",
    "1. Set up the wellness research request\n",
    "2. Configure the execution with Anthropic settings\n",
    "3. Run the research workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Graph ready for execution\n",
      "  (Note: The graph is pre-compiled from the library)\n"
     ]
    }
   ],
   "source": [
    "# Set up the graph with Anthropic configuration\n",
    "from IPython.display import Markdown, display\n",
    "import uuid\n",
    "\n",
    "# Note: deep_researcher is already compiled from the library\n",
    "# For this demo, we'll use it directly without additional checkpointing\n",
    "graph = deep_researcher\n",
    "\n",
    "print(\"‚úì Graph ready for execution\")\n",
    "print(\"  (Note: The graph is pre-compiled from the library)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration for Anthropic\n",
    "\n",
    "We'll configure the system to use:\n",
    "- **Claude Sonnet 4** for all research, supervision, and report generation\n",
    "- **Tavily** for web search (you can also use Anthropic's native search)\n",
    "- **Moderate parallelism** (1 concurrent researcher for cost control)\n",
    "- **Clarification enabled** (will ask if research scope is unclear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Configuration ready\n",
      "  - Research Model: Claude Sonnet 4\n",
      "  - Max Concurrent Researchers: 1\n",
      "  - Max Iterations: 2\n",
      "  - Search API: Tavily\n"
     ]
    }
   ],
   "source": [
    "# Configure for Anthropic with moderate settings\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        # Model configuration - using Claude Sonnet 4 for everything\n",
    "        \"research_model\": \"anthropic:claude-sonnet-4-20250514\",\n",
    "        \"research_model_max_tokens\": 10000,\n",
    "        \n",
    "        \"compression_model\": \"anthropic:claude-sonnet-4-20250514\",\n",
    "        \"compression_model_max_tokens\": 8192,\n",
    "        \n",
    "        \"final_report_model\": \"anthropic:claude-sonnet-4-20250514\",\n",
    "        \"final_report_model_max_tokens\": 10000,\n",
    "        \n",
    "        \"summarization_model\": \"anthropic:claude-sonnet-4-20250514\",\n",
    "        \"summarization_model_max_tokens\": 8192,\n",
    "        \n",
    "        # Research behavior\n",
    "        \"allow_clarification\": True,\n",
    "        \"max_concurrent_research_units\": 1,  # 1 parallel researcher\n",
    "        \"max_researcher_iterations\": 2,      # Supervisor can delegate up to 2 times\n",
    "        \"max_react_tool_calls\": 3,           # Each researcher can make up to 3 tool calls\n",
    "        \n",
    "        # Search configuration\n",
    "        \"search_api\": \"tavily\",  # Using Tavily for web search\n",
    "        \"max_content_length\": 50000,\n",
    "        \n",
    "        # Thread ID for this conversation\n",
    "        \"thread_id\": str(uuid.uuid4())\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚úì Configuration ready\")\n",
    "print(f\"  - Research Model: Claude Sonnet 4\")\n",
    "print(f\"  - Max Concurrent Researchers: 1\")\n",
    "print(f\"  - Max Iterations: 2\")\n",
    "print(f\"  - Search API: Tavily\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the Wellness Research\n",
    "\n",
    "Now let's run the research! We'll ask the system to research evidence-based strategies for improving sleep quality.\n",
    "\n",
    "The workflow will:\n",
    "1. **Clarify** - Check if the request is clear (may skip if obvious)\n",
    "2. **Research Brief** - Transform our request into a structured brief\n",
    "3. **Supervisor** - Plan research strategy and delegate to researchers\n",
    "4. **Parallel Research** - Researchers gather information simultaneously\n",
    "5. **Compression** - Each researcher synthesizes their findings\n",
    "6. **Final Report** - All findings combined into comprehensive report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting research workflow...\n",
      "\n",
      "\n",
      "============================================================\n",
      "Node: clarify_with_user\n",
      "============================================================\n",
      "\n",
      "I have sufficient information to proceed with your sleep improvement research. I understand you're looking for evidence-based strategies to address your current sleep challenges: inconsistent bedtimes (10pm-1am), phone use in bed, and morning fatigue. I'll research comprehensive, scientifically-backed sleep hygiene practices and create a personalized sleep improvement plan that addresses these specific issues. Beginning research now.\n",
      "\n",
      "============================================================\n",
      "Node: write_research_brief\n",
      "============================================================\n",
      "\n",
      "Research Brief Generated:\n",
      "I want to improve my sleep quality based on evidence-based strategies. I currently have three main issues: (1) inconsistent bedtimes ranging from 10pm to 1am, (2) using my phone in bed, and (3) often feeling tired in the morning despite sleeping. Please research comprehensive, scientifically-backed sleep hygiene practices and create a personalized sleep improvement plan that specifically addresses these issues. The research should focus on peer-reviewed studies and clinical evidence from sleep m...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Summarization failed with error: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': \"This request would exceed your organization's rate limit of 30,000 input tokens per minute (org: 9f1a99aa-e76c-4b5d-ac9e-e7690fd731fb, model: claude-sonnet-4-20250514). For details, refer to: https://docs.claude.com/en/api/rate-limits. You can see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.\"}, 'request_id': 'req_011CXwBQ9Cyu5dDDgDjNuFBz'}, returning original content\n",
      "WARNING:root:Summarization failed with error: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': \"This request would exceed your organization's rate limit of 30,000 input tokens per minute (org: 9f1a99aa-e76c-4b5d-ac9e-e7690fd731fb, model: claude-sonnet-4-20250514). For details, refer to: https://docs.claude.com/en/api/rate-limits. You can see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.\"}, 'request_id': 'req_011CXwBRTvQAsTB6t7tQKLcE'}, returning original content\n",
      "WARNING:root:Summarization failed with error: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': \"This request would exceed your organization's rate limit of 30,000 input tokens per minute (org: 9f1a99aa-e76c-4b5d-ac9e-e7690fd731fb, model: claude-sonnet-4-20250514). For details, refer to: https://docs.claude.com/en/api/rate-limits. You can see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.\"}, 'request_id': 'req_011CXwBdNY31iepXmoQYoYyw'}, returning original content\n",
      "WARNING:root:Summarization failed with error: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': \"This request would exceed your organization's rate limit of 30,000 input tokens per minute (org: 9f1a99aa-e76c-4b5d-ac9e-e7690fd731fb, model: claude-sonnet-4-20250514). For details, refer to: https://docs.claude.com/en/api/rate-limits. You can see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.\"}, 'request_id': 'req_011CXwBdVQHFeVe1fvjgx6Eg'}, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Node: research_supervisor\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Node: final_report_generation\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "FINAL REPORT GENERATED\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Evidence-Based Sleep Improvement Plan: Addressing Inconsistent Bedtimes, Phone Use, and Morning Fatigue\n",
       "\n",
       "## Understanding Your Sleep Challenges\n",
       "\n",
       "Your three primary sleep issues‚Äîinconsistent bedtimes, phone use in bed, and morning fatigue‚Äîare interconnected problems rooted in circadian rhythm disruption and poor sleep hygiene practices. Research shows that sleep consistency refers to maintaining the same bedtime and wake-up time within 30 minutes, including weekends, and this consistency is crucial for health, safety, and performance [1]. A 2023 study found that students with irregular sleep patterns had lower academic performance and more mental health challenges than peers with consistent sleep, even when both groups slept for similar durations [2].\n",
       "\n",
       "The 3-hour variability in your bedtime (10pm-1am) significantly disrupts your circadian rhythm, which requires daily adjustment since the endogenous human physiological cycle is slightly longer than 24 hours. This coordination is achieved through the suprachiasmatic nucleus (SCN) in the anterior hypothalamus, your body's central pacemaker [3]. When this system is disrupted by irregular timing and blue light exposure from devices, it creates a cascade of sleep problems including difficulty falling asleep, poor sleep quality, and morning fatigue.\n",
       "\n",
       "## Establishing Consistent Sleep Schedules\n",
       "\n",
       "### The Science of Sleep Consistency\n",
       "\n",
       "The circadian photoreceptor system shows peak sensitivity to 450-480 nm light within the blue spectrum, which accounts for blue light's high efficacy in suppressing melatonin and increasing alertness [4]. Your inconsistent bedtime pattern suggests a delayed sleep-wake phase, which affects up to 78% of individuals with sleep timing issues. Research indicates that approximately 40% of people with delayed sleep phase disorder have a family history of circadian rhythm sleep disorders [5].\n",
       "\n",
       "### Evidence-Based Schedule Fixing Protocol\n",
       "\n",
       "**Step 1: Establish a Fixed Wake-Up Time First**\n",
       "Research demonstrates that focusing first on establishing a fixed wake-up time is more effective than trying to control bedtime. Choose a wake-up time that allows for at least 7-9 hours of sleep and maintain it every day, including weekends [6].\n",
       "\n",
       "**Step 2: Gradual Bedtime Adjustment**\n",
       "Make gradual adjustments in 15-30 minute increments over several days rather than dramatic changes. If you're currently going to bed at 1am but want to sleep by 10pm, move your bedtime 30 minutes earlier every 2-3 days until you reach your target [6].\n",
       "\n",
       "**Step 3: Light Exposure Timing**\n",
       "Light exposure is the most powerful zeitgeber (time cue) for circadian rhythms. Studies show that morning light exposure can advance sleep timing, while evening light delays it. A week of natural light-dark cycle exposure advanced dim light melatonin onset (DLMO) by approximately 2.6 hours in healthy adults [7].\n",
       "\n",
       "### Chronotherapy and Advanced Timing Interventions\n",
       "\n",
       "For severe timing issues, chronotherapy involves gradually postponing sleep time by 3 hours every 2-5 days until reaching the desired schedule. However, this requires careful planning and is typically done under medical supervision [5]. A more practical approach combines morning bright light therapy with evening light restriction. Studies using 10,000 lux morning light therapy showed phase advances of 31 minutes in DLMO and 57 minutes in mid-sleep time [7].\n",
       "\n",
       "## Managing Electronic Device Use Before Bedtime\n",
       "\n",
       "### The Blue Light Problem\n",
       "\n",
       "Multiple studies demonstrate that blue light exposure suppresses melatonin secretion and exacerbates sleep problems. Evening exposure to LED-backlit devices can suppress and delay melatonin production, making it significantly harder to fall asleep [4]. A systematic review found that blue light exposure decreased sleep quality in one-fifth of studies and decreased sleep duration in one-third of studies [8].\n",
       "\n",
       "### Evidence-Based Device Management Strategies\n",
       "\n",
       "**Complete Device Elimination Protocol**\n",
       "The most effective approach is complete elimination of screens 1-2 hours before bedtime. Reserve this hour for wind-down activities away from stimulating content [9]. Replace phone use with reading physical books, gentle stretching, meditation, or other relaxing activities.\n",
       "\n",
       "**Blue Light Filtering Solutions**\n",
       "If complete elimination isn't immediately feasible, research shows specific interventions can help:\n",
       "\n",
       "- **Blue Light Blocking Glasses**: A randomized controlled trial found that wearing amber-tinted blue light-blocking lenses for 2 hours before bedtime for 7 consecutive nights significantly improved multiple sleep measures, including sleep quality, duration, soundness, and reduced overall sleep distress [4].\n",
       "\n",
       "- **Device Settings**: Use \"warm\" lighting settings on devices. Studies show that \"cool\" white LED lights caused 12.3% melatonin suppression compared to just 3.6% for \"warm\" white LEDs. Tunable LED devices can reduce estimated melatonin suppression from 10% at cool settings to just 0.1% at warm settings [10].\n",
       "\n",
       "**Environmental Light Management**\n",
       "Research indicates that only brown-tinted blue light filtering solutions proved highly effective, reducing estimated melatonin suppression to below 0.3%. Additionally, bedroom lighting should transition to warm, dim lighting 2-3 hours before bedtime [10].\n",
       "\n",
       "## Addressing Morning Fatigue and Sleep Quality Optimization\n",
       "\n",
       "### Understanding Sleep Architecture and Morning Fatigue\n",
       "\n",
       "Morning fatigue despite adequate sleep duration typically indicates poor sleep quality or disrupted sleep architecture. Sleep architecture consists of 4-6 cycles lasting 90-120 minutes each, including Non-REM sleep (light stages 1-2 and deep slow-wave stage 3) and REM sleep. Research published in Sleep Medicine Reviews demonstrates that sleep quality is just as important as sleep duration for feeling refreshed [11].\n",
       "\n",
       "### Sleep Inertia and Cortisol Response\n",
       "\n",
       "Sleep inertia, the grogginess experienced upon waking, was first identified among U.S. Air Force pilots in the 1950s. It's most likely to occur with sudden awakening or insufficient sleep and may last from minutes to over an hour [12]. This is often related to disrupted cortisol awakening response, which should peak within 30-45 minutes after morning awakening and then decline throughout the day.\n",
       "\n",
       "### Strategies for Reducing Morning Fatigue\n",
       "\n",
       "**Optimize Sleep Timing**\n",
       "Waking during lighter sleep stages reduces sleep inertia. While you can't control this precisely without sleep tracking devices, maintaining consistent timing helps your body naturally optimize awakening timing.\n",
       "\n",
       "**Address Sleep Architecture Issues**\n",
       "Deep sleep is when your body repairs tissues, strengthens immunity, and consolidates memories. Insufficient deep sleep leads to morning fatigue regardless of total duration [11]. Factors that improve deep sleep include:\n",
       "- Consistent sleep timing\n",
       "- Optimal bedroom temperature (65¬∞F/18.3¬∞C)\n",
       "- Complete darkness\n",
       "- Minimal noise disruption\n",
       "- Regular exercise (but not within 3-4 hours of bedtime)\n",
       "\n",
       "**Morning Light Exposure**\n",
       "Immediate bright light exposure upon awakening helps establish proper cortisol awakening response and reinforces circadian timing. Studies show this can advance sleep phase and improve morning alertness [7].\n",
       "\n",
       "## Bedroom Environment Optimization\n",
       "\n",
       "### Temperature Control\n",
       "\n",
       "Research consistently shows that people sleep better when their bedroom is optimized for temperature. Any healthy adult experiences a natural drop in body temperature during sleep, which occurs during initial sleep stages because lower core temperature promotes sleepiness. Many experts agree that 65¬∞F (18.3¬∞C) is the ideal bedroom temperature, though this may seem cool, it helps maintain lower core temperature during sleep [13].\n",
       "\n",
       "### Noise Management\n",
       "\n",
       "Studies demonstrate that even low-level noise can cause shifts to lighter sleep stages or momentary awakenings. Research examining bedroom environmental factors found that sleep efficiency was significantly related to noise levels (P <.0001), with noise having a -1.85% impact on sleep efficacy after statistical adjustment [14]. Strategies include:\n",
       "- Use of white noise machines or earplugs\n",
       "- Heavy curtains or sound-dampening materials\n",
       "- Addressing sources of intermittent noise\n",
       "\n",
       "### Light Control\n",
       "\n",
       "Circadian rhythms are heavily influenced by light and darkness. During the day, sunlight signals the brain to produce cortisol for alertness, while darkness triggers melatonin production for sleepiness. Artificial light exposure in the evening delays circadian rhythms and prolongs sleep onset [13]. Create complete darkness using blackout curtains, eye masks, and elimination of LED indicator lights from electronics.\n",
       "\n",
       "### Air Quality Considerations\n",
       "\n",
       "Recent research shows that bedroom air quality significantly affects sleep. In fully adjusted statistical models, sleep efficacy was related to PM2.5 particles (P <.05), CO2 levels (P <.05), and temperature (P <.05). After statistical transformation, sleep efficacy decreased by 2.15% with PM2.5 exposure and 1.73% with temperature increases [14]. Consider air purifiers and adequate ventilation.\n",
       "\n",
       "## Comprehensive Implementation Plan\n",
       "\n",
       "### Phase 1: Immediate Changes (Week 1-2)\n",
       "\n",
       "**Sleep Timing Foundation**\n",
       "- Choose a fixed wake-up time that allows 7-9 hours of sleep\n",
       "- Set this wake-up time for every day, including weekends\n",
       "- Begin moving bedtime 30 minutes earlier every 2-3 days if currently going to bed after 11pm\n",
       "\n",
       "**Device Management**\n",
       "- Implement complete phone/device ban in the bedroom\n",
       "- Charge devices in another room\n",
       "- Replace bedtime phone use with reading, gentle stretching, or meditation\n",
       "- If immediate elimination isn't possible, use amber-tinted blue light blocking glasses 2 hours before bedtime\n",
       "\n",
       "**Environment Setup**\n",
       "- Set bedroom temperature to 65¬∞F (18.3¬∞C)\n",
       "- Install blackout curtains or use eye masks\n",
       "- Remove or cover LED lights from electronics\n",
       "- Ensure bedroom is as quiet as possible\n",
       "\n",
       "### Phase 2: Optimization (Week 3-4)\n",
       "\n",
       "**Light Exposure Protocol**\n",
       "- Get bright light exposure within 30 minutes of waking (natural sunlight preferred, or 10,000 lux light therapy device)\n",
       "- Dim all lights to warm settings 2-3 hours before bedtime\n",
       "- Use only amber or red lighting in evening hours\n",
       "\n",
       "**Sleep Hygiene Refinement**\n",
       "- Establish a consistent 1-hour pre-sleep routine including relaxing activities\n",
       "- Avoid caffeine after 2pm\n",
       "- Avoid large meals, alcohol, and intense exercise within 3-4 hours of bedtime\n",
       "- Consider room temperature water beside bed to avoid middle-of-night searches\n",
       "\n",
       "### Phase 3: Advanced Interventions (Week 5+)\n",
       "\n",
       "**Circadian Support**\n",
       "- If sleep timing issues persist, consider low-dose melatonin (0.5-3mg) taken 2-3 hours before desired bedtime, but consult healthcare provider first\n",
       "- Track sleep patterns to identify optimal timing\n",
       "- Consider morning exercise to strengthen circadian signals\n",
       "\n",
       "**Environmental Fine-Tuning**\n",
       "- Address air quality with purifiers or plants if needed\n",
       "- Experiment with white noise or earplugs for noise management\n",
       "- Ensure mattress and pillows support comfortable, uninterrupted sleep\n",
       "\n",
       "### Monitoring and Adjustment\n",
       "\n",
       "Track your sleep using a simple log noting bedtime, wake time, sleep quality (1-10 scale), morning fatigue levels, and any deviations from the protocol. Research shows that knowledge alone doesn't translate to improved sleep quality‚Äîit requires behavioral change and planned actions for success [15]. Sleep is highly individual, highlighting why precision medicine approaches are key to sleep hygiene success.\n",
       "\n",
       "Expect gradual improvement over 2-4 weeks rather than immediate results. Studies indicate that circadian rhythm adjustments take time, with some interventions showing effects within days while others require weeks of consistency. The key is maintaining the protocol even when results aren't immediately apparent, as circadian rhythm entrainment is a gradual biological process.\n",
       "\n",
       "### Sources\n",
       "\n",
       "[1] The importance of sleep regularity: a consensus statement: https://www.researchgate.net/publication/373741330_The_importance_of_sleep_regularity_a_consensus_statement_of_the_National_Sleep_Foundation_sleep_timing_and_variability_panel\n",
       "\n",
       "[2] The Science Behind Sleep Consistency and Timing: https://villagedoctor.com/unlock-better-restscience-behind-sleep-consistency/\n",
       "\n",
       "[3] Treatment of Circadian Rhythm Sleep‚ÄìWake Disorders: https://pmc.ncbi.nlm.nih.gov/articles/PMC9886819/\n",
       "\n",
       "[4] Blocking nocturnal blue light for insomnia: A randomized controlled trial: https://www.sciencedirect.com/science/article/abs/pii/S0022395617308592\n",
       "\n",
       "[5] Treatment of Circadian Rhythm Sleep‚ÄìWake Disorders: https://pmc.ncbi.nlm.nih.gov/articles/PMC9886819/\n",
       "\n",
       "[6] How to Fix Your Sleep Schedule: https://www.sleepfoundation.org/sleep-hygiene/how-to-reset-your-sleep-routine\n",
       "\n",
       "[7] ADHD as a circadian rhythm disorder: evidence and implications for chronotherapy: https://www.frontiersin.org/journals/psychiatry/articles/10.3389/fpsyt.2025.1697900/full\n",
       "\n",
       "[8] The influence of blue light on sleep, performance and wellbeing: https://pmc.ncbi.nlm.nih.gov/articles/PMC9424753/\n",
       "\n",
       "[9] Sleep hygiene: Simple practices for better rest: https://www.health.harvard.edu/staying-healthy/sleep-hygiene-simple-practices-for-better-rest\n",
       "\n",
       "[10] The influence of blue light on sleep, performance and wellbeing: https://pmc.ncbi.nlm.nih.gov/articles/PMC9424753/\n",
       "\n",
       "[11] Why Do I Always Wake Up Tired?: https://www.thesleepreset.com/blog/wake-up-tired\n",
       "\n",
       "[12] Sleep Inertia: Symptoms, Causes, and More: https://www.verywellhealth.com/how-does-sleep-inertia-make-it-hard-to-wake-up-3014826\n",
       "\n",
       "[13] Sleep hygiene: Simple practices for better rest: https://www.health.harvard.edu/staying-healthy/sleep-hygiene-simple-practices-for-better-rest\n",
       "\n",
       "[14] New research on bedroom ventilation and sleep quality: https://www.tandfonline.com/doi/full/10.1080/23744731.2025.2531317\n",
       "\n",
       "[15] Sleep Hygiene Practices: Where to Now?: https://www.mdpi.com/2673-947X/2/3/13"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Research workflow completed!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Create our wellness research request\n",
    "research_request = \"\"\"\n",
    "I want to improve my sleep quality. I currently:\n",
    "- Go to bed at inconsistent times (10pm-1am)\n",
    "- Use my phone in bed\n",
    "- Often feel tired in the morning\n",
    "\n",
    "Please research the best evidence-based strategies for improving sleep quality and create a comprehensive sleep improvement plan for me.\n",
    "\"\"\"\n",
    "\n",
    "# Execute the graph\n",
    "async def run_research():\n",
    "    \"\"\"Run the research workflow and display results.\"\"\"\n",
    "    print(\"Starting research workflow...\\n\")\n",
    "    \n",
    "    async for event in graph.astream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": research_request}]},\n",
    "        config,\n",
    "        stream_mode=\"updates\"\n",
    "    ):\n",
    "        # Display each step\n",
    "        for node_name, node_output in event.items():\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Node: {node_name}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            if node_name == \"clarify_with_user\":\n",
    "                if \"messages\" in node_output:\n",
    "                    last_msg = node_output[\"messages\"][-1]\n",
    "                    print(f\"\\n{last_msg.content}\")\n",
    "            \n",
    "            elif node_name == \"write_research_brief\":\n",
    "                if \"research_brief\" in node_output:\n",
    "                    print(f\"\\nResearch Brief Generated:\")\n",
    "                    print(f\"{node_output['research_brief'][:500]}...\")\n",
    "            \n",
    "            elif node_name == \"supervisor\":\n",
    "                print(f\"\\nSupervisor planning research strategy...\")\n",
    "                if \"supervisor_messages\" in node_output:\n",
    "                    last_msg = node_output[\"supervisor_messages\"][-1]\n",
    "                    if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:\n",
    "                        print(f\"Tool calls: {len(last_msg.tool_calls)}\")\n",
    "                        for tc in last_msg.tool_calls:\n",
    "                            print(f\"  - {tc['name']}\")\n",
    "            \n",
    "            elif node_name == \"supervisor_tools\":\n",
    "                print(f\"\\nExecuting supervisor's tool calls...\")\n",
    "                if \"notes\" in node_output:\n",
    "                    print(f\"Research notes collected: {len(node_output['notes'])}\")\n",
    "            \n",
    "            elif node_name == \"final_report_generation\":\n",
    "                if \"final_report\" in node_output:\n",
    "                    print(f\"\\n\" + \"=\"*60)\n",
    "                    print(\"FINAL REPORT GENERATED\")\n",
    "                    print(\"=\"*60 + \"\\n\")\n",
    "                    display(Markdown(node_output[\"final_report\"]))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Research workflow completed!\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Run the research\n",
    "await run_research()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9: Understanding the Output\n",
    "\n",
    "Let's break down what happened:\n",
    "\n",
    "### Phase 1: Clarification\n",
    "The system checked if your request was clear. Since you provided specific details about your sleep issues, it likely proceeded without asking clarifying questions.\n",
    "\n",
    "### Phase 2: Research Brief\n",
    "Your request was transformed into a detailed research brief that guides the supervisor's delegation strategy.\n",
    "\n",
    "### Phase 3: Supervisor Delegation\n",
    "The supervisor analyzed the brief and decided how to break down the research:\n",
    "- Used `think_tool` to plan strategy\n",
    "- Called `ConductResearch` to delegate to researchers\n",
    "- Each delegation specified a focused research topic (e.g., sleep hygiene, circadian rhythm, blue light effects)\n",
    "\n",
    "### Phase 4: Parallel Research\n",
    "Researchers worked on their assigned topics:\n",
    "- Each researcher used web search tools to gather information\n",
    "- Used `think_tool` to reflect after each search\n",
    "- Decided when they had enough information\n",
    "- Compressed their findings into clean summaries\n",
    "\n",
    "### Phase 5: Final Report\n",
    "All research findings were synthesized into a comprehensive sleep improvement plan with:\n",
    "- Well-structured sections\n",
    "- Evidence-based recommendations\n",
    "- Practical action items\n",
    "- Sources for further reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10: Key Takeaways & Next Steps\n",
    "\n",
    "### Architecture Benefits\n",
    "1. **Dynamic Decomposition** - Research structure emerges from the question, not predefined\n",
    "2. **Parallel Efficiency** - Multiple researchers work simultaneously\n",
    "3. **ReAct Quality** - Strategic reflection improves search decisions\n",
    "4. **Scalability** - Handles token limits gracefully through compression\n",
    "5. **Flexibility** - Easy to add new tools and capabilities\n",
    "\n",
    "### When to Use This Pattern\n",
    "- **Complex research questions** that need multi-angle investigation\n",
    "- **Comparison tasks** where parallel research on different topics is beneficial\n",
    "- **Open-ended exploration** where structure should emerge dynamically\n",
    "- **Time-sensitive research** where parallel execution speeds up results\n",
    "\n",
    "### When to Use Section-Based Instead\n",
    "- **Highly structured reports** with predefined format requirements\n",
    "- **Template-based content** where sections are always the same\n",
    "- **Sequential dependencies** where later sections depend on earlier ones\n",
    "- **Budget constraints** where token efficiency is critical\n",
    "\n",
    "### Extend the System\n",
    "1. **Add MCP Tools** - Integrate specialized tools for your domain\n",
    "2. **Custom Prompts** - Modify prompts for specific research types\n",
    "3. **Different Models** - Try different Claude versions or mix models\n",
    "4. **Persistence** - Use a real database for checkpointing instead of memory\n",
    "\n",
    "### Learn More\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "- [Open Deep Research Repo](https://github.com/langchain-ai/open_deep_research)\n",
    "- [Anthropic Claude Documentation](https://docs.anthropic.com/)\n",
    "- [Tavily Search API](https://tavily.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùì Question #3:\n",
    "\n",
    "What are the trade-offs of using parallel researchers vs. sequential research? When might you choose one approach over the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer:\n",
    "Trade-offs of Parallel vs Sequential Research:\n",
    "- Speed vs. Cost/Complexity: Parallel is faster because you can have 5 agents searching 5 different topics at once. The downside occurs in complexity and potential rate-limiting. You burn through tokens much faster in a short burst, which might hit API limits or cost more per minute.\n",
    "- Context Isolation: In parallel research, Agent A doesn't know what Agent B is finding until the end. In sequential research, Agent B can learn from what Agent A found and adjust its search strategy, which is better for \"follow-up\" type investigations.\n",
    "\n",
    "When to choose one over the other:\n",
    "- Choose Parallel when you have distinct, non-overlapping topics. For example, \"Compare the pricing of AWS, Azure, and Google Cloud.\" You don't need to know AWS's price to look up Azure's. It's distinct lists or comparisons.\n",
    "- Choose Sequential when the research is a \"chain\" of dependencies. For example, \"Find out who the CEO of Company X is, and then find their recent interviews.\" You can't do the second part until the first part is done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùì Question #4:\n",
    "\n",
    "How would you adapt this deep research architecture for a production wellness application? What additional components would you need?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer:\n",
    "To adapt this for a production wellness application, we would need several critical additions beyond the prototype:\n",
    "\n",
    "- Safety & Medical Disclaimers: Since this is health-related, we need a robust moderation layer. We can't just let the LLM give advice unchecked. We'd need a \"Safety Check\" node that runs before the final report to ensure no harmful or hallucinations of medical advice are output.\n",
    "- User Context Integration (The \"Wellness Profile\"): Instead of just taking a raw query, the system should pull from a user database. If I ask for a diet plan, it should already know my allergies, age, and activity level. This would be a \"Context Retrieval\" node added to the start of the graph.\n",
    "- Persistence: The current MemorySaver is in-memory and temporary. For production, we need a lasting database (like Postgres with langgraph-checkpoint-postgres) so users can pause a research task and come back to it days later.\n",
    "- Caching: Many users will ask similar questions (e.g., \"how to sleep better\"). We don't want to pay for all the web searches every single time. A semantic cache would check if a similar research report already exists before starting a new one.\n",
    "- Feedback Loop: We need a way for users to rate the advice. This feedback should be saved and used to fine-tune the supervisor or researcher prompts over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Activity #2: Custom Wellness Research\n",
    "\n",
    "Using what you've learned, run a custom wellness research task.\n",
    "\n",
    "**Requirements:**\n",
    "1. Create a wellness-related research question (exercise, nutrition, stress, etc.)\n",
    "2. Modify the configuration for your use case\n",
    "3. Run the research and analyze the output\n",
    "4. Document what worked well and what could be improved\n",
    "\n",
    "**Experiment ideas:**\n",
    "- Research exercise routines for specific conditions (bad knee, lower back pain)\n",
    "- Compare different stress management techniques\n",
    "- Investigate nutrition strategies for specific goals\n",
    "- Explore meditation and mindfulness research\n",
    "\n",
    "**YOUR CODE HERE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting custom wellness research...\n",
      "\n",
      "\n",
      "============================================================\n",
      "Node: clarify_with_user\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Node: write_research_brief\n",
      "============================================================\n",
      "\n",
      "Research Brief Generated:\n",
      "I have mild patellofemoral pain syndrome and need to transition from my previous running routine (3x per week) to knee-friendly alternatives while maintaining cardiovascular fitness and leg strength. I have access to a gym with machines, free weights, and a pool. Please research and provide evidence-based recommendations for: (1) Low-impact cardiovascular exercise alternatives to running that are specifically safe for patellofemoral pain syndrome, including detailed guidance on frequency, intens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Node: research_supervisor\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Node: final_report_generation\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "FINAL REPORT GENERATED\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Error generating final report: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': \"This request would exceed your organization's rate limit of 30,000 input tokens per minute (org: 9f1a99aa-e76c-4b5d-ac9e-e7690fd731fb, model: claude-sonnet-4-20250514). For details, refer to: https://docs.claude.com/en/api/rate-limits. You can see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.\"}, 'request_id': 'req_011CXwCQei8FBBjaJfxcetXZ'}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Research workflow completed!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Research exercise routines for specific conditions (bad knee)\n",
    "my_wellness_request = \"\"\"\n",
    "I have a bad knee (mild patellofemoral pain syndrome) and want to stay active.\n",
    "My current situation:\n",
    "- I used to run 3x per week but had to stop due to knee pain\n",
    "- I have access to a gym with machines, free weights, and a pool\n",
    "- My goal is to maintain cardiovascular fitness and leg strength without aggravating my knee\n",
    "\n",
    "Please research:\n",
    "1. Evidence-based low-impact cardio alternatives to running (especially for knee-friendly options)\n",
    "2. Safe leg strengthening exercises that protect the patellofemoral joint\n",
    "3. Any stretching or mobility routines that help with patellofemoral pain syndrome\n",
    "\"\"\"\n",
    "\n",
    "# Modified configuration for this use case\n",
    "my_config = {\n",
    "    \"configurable\": {\n",
    "        \"research_model\": \"anthropic:claude-sonnet-4-20250514\",\n",
    "        \"research_model_max_tokens\": 10000,\n",
    "        \"compression_model\": \"anthropic:claude-sonnet-4-20250514\",\n",
    "        \"compression_model_max_tokens\": 8192,\n",
    "        \"final_report_model\": \"anthropic:claude-sonnet-4-20250514\",\n",
    "        \"final_report_model_max_tokens\": 10000,\n",
    "        \"summarization_model\": \"anthropic:claude-sonnet-4-20250514\",\n",
    "        \"summarization_model_max_tokens\": 8192,\n",
    "        \"allow_clarification\": False,  # Disabled - we provided detailed context\n",
    "        \"max_concurrent_research_units\": 2,  # 2 parallel researchers\n",
    "        \"max_researcher_iterations\": 3,\n",
    "        \"max_react_tool_calls\": 4,\n",
    "        \"search_api\": \"tavily\",\n",
    "        \"max_content_length\": 50000,\n",
    "        \"thread_id\": str(uuid.uuid4())\n",
    "    }\n",
    "}\n",
    "\n",
    "# Run the research\n",
    "async def run_custom_research():\n",
    "    \"\"\"Run the custom wellness research workflow.\"\"\"\n",
    "    print(\"Starting custom wellness research...\\n\")\n",
    "    \n",
    "    async for event in graph.astream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": my_wellness_request}]},\n",
    "        my_config,\n",
    "        stream_mode=\"updates\"\n",
    "    ):\n",
    "        for node_name, node_output in event.items():\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Node: {node_name}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            # Skip if node_output is None\n",
    "            if node_output is None:\n",
    "                continue\n",
    "            \n",
    "            if node_name == \"clarify_with_user\":\n",
    "                if \"messages\" in node_output and node_output[\"messages\"]:\n",
    "                    last_msg = node_output[\"messages\"][-1]\n",
    "                    print(f\"\\n{last_msg.content}\")\n",
    "            \n",
    "            elif node_name == \"write_research_brief\":\n",
    "                if \"research_brief\" in node_output and node_output[\"research_brief\"]:\n",
    "                    print(f\"\\nResearch Brief Generated:\")\n",
    "                    print(f\"{node_output['research_brief'][:500]}...\")\n",
    "            \n",
    "            elif node_name == \"supervisor\":\n",
    "                print(f\"\\nSupervisor planning research strategy...\")\n",
    "            \n",
    "            elif node_name == \"final_report_generation\":\n",
    "                if \"final_report\" in node_output and node_output[\"final_report\"]:\n",
    "                    print(f\"\\n\" + \"=\"*60)\n",
    "                    print(\"FINAL REPORT GENERATED\")\n",
    "                    print(\"=\"*60 + \"\\n\")\n",
    "                    display(Markdown(node_output[\"final_report\"]))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Research workflow completed!\")\n",
    "    print(\"=\"*60)\n",
    "await run_custom_research()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What worked well: The research brief correctly captured my question and the graph ran end-to-end through all nodes.\n",
    "\n",
    "What could be improved:\n",
    "\n",
    "- Rate limits: Hit a 429 error and I should have used max_concurrent_research_units: 1 on free tier\n",
    "- Timeouts: 16 summarization timeouts make me think maybe I should use lower max_content_length next time\n",
    "- Error handling: Final report just showed raw error instead of returning partial results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
