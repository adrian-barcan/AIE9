{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCk2Rx4cjlYF"
   },
   "source": [
    "# Session 9: Synthetic Data Generation and RAG Evaluation with LangSmith\n",
    "\n",
    "In the following notebook we'll explore a use-case for RAGAS' synthetic testset generation workflow, and use it to evaluate and iterate on a RAG pipeline with LangSmith!\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand Ragas' knowledge graph-based synthetic data generation workflow\n",
    "- Generate synthetic test sets with different query synthesizer types\n",
    "- Load synthetic data into LangSmith for evaluation\n",
    "- Evaluate a RAG chain using LangSmith evaluators\n",
    "- Iterate on RAG pipeline parameters and measure the impact\n",
    "\n",
    "## Table of Contents:\n",
    "\n",
    "- **Breakout Room #1:** Synthetic Data Generation with Ragas\n",
    "  - Task 1: Dependencies and API Keys\n",
    "  - Task 2: Data Preparation and Knowledge Graph Construction\n",
    "  - Task 3: Generating Synthetic Test Data\n",
    "  - Question #1 & Question #2\n",
    "  - üèóÔ∏è Activity #1: Custom Query Distribution\n",
    "\n",
    "- **Breakout Room #2:** RAG Evaluation with LangSmith\n",
    "  - Task 4: LangSmith Dataset Setup\n",
    "  - Task 5: Building a Basic RAG Chain\n",
    "  - Task 6: Evaluating with LangSmith\n",
    "  - Task 7: Modifying the Pipeline and Re-Evaluating\n",
    "  - Question #3 & Question #4\n",
    "  - üèóÔ∏è Activity #2: Analyze Evaluation Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bG2ta-B478G"
   },
   "source": [
    "---\n",
    "# ü§ù Breakout Room #1\n",
    "## Synthetic Data Generation with Ragas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VUI7vF_kbv9"
   },
   "source": [
    "## Task 1: Dependencies and API Keys\n",
    "\n",
    "We'll need to install a number of API keys and dependencies, since we'll be leveraging a number of great technologies for this pipeline!\n",
    "\n",
    "1. OpenAI's endpoints to handle the Synthetic Data Generation\n",
    "2. OpenAI's Endpoints for our RAG pipeline and LangSmith evaluation\n",
    "3. QDrant as our vectorstore\n",
    "4. LangSmith for our evaluation coordinator!\n",
    "\n",
    "Let's install and provide all the required information below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies and API Keys:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Import\n",
    "\n",
    "To prevent errors that may occur based on OS - we'll import NLTK and download the needed packages to ensure correct handling of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/adrianbarcan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/adrianbarcan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also want to set a project name to make things easier for ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIM - SDG - {uuid4().hex[0:8]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI's API Key!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Synthetic Test Data\n",
    "\n",
    "We wil be using Ragas to build out a set of synthetic test questions, references, and reference contexts. This is useful because it will allow us to find out how our system is performing.\n",
    "\n",
    "> NOTE: Ragas is best suited for finding *directional* changes in your LLM-based systems. The absolute scores aren't comparable in a vacuum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "We'll prepare our data using two complementary guides ‚Äî a Health & Wellness Guide covering exercise, nutrition, sleep, and stress management, and a Mental Health & Psychology Handbook covering mental health conditions, therapeutic approaches, resilience, and daily mental health practices. The topical overlap between documents helps RAGAS build rich cross-document relationships in the knowledge graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load our data into a familiar LangChain format using the `TextLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents: ['data/MentalHealthGuide.txt', 'data/HealthWellnessGuide.txt']\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "loader = DirectoryLoader(\"data/\", glob=\"*.txt\", loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "print(f\"Loaded {len(docs)} documents: {[d.metadata['source'] for d in docs]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Graph Based Synthetic Generation\n",
    "\n",
    "Ragas uses a knowledge graph based approach to create data. This is extremely useful as it allows us to create complex queries rather simply. The additional testset complexity allows us to evaluate larger problems more effectively, as systems tend to be very strong on simple evaluation tasks.\n",
    "\n",
    "Let's start by defining our `generator_llm` (which will generate our questions, summaries, and more), and our `generator_embeddings` which will be useful in building our graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unrolled SDG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to instantiate our Knowledge Graph.\n",
    "\n",
    "This graph will contain N number of nodes that have M number of relationships. These nodes and relationships (AKA \"edges\") will define our knowledge graph and be used later to construct relevant questions and responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 0, relationships: 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.graph import KnowledgeGraph\n",
    "\n",
    "kg = KnowledgeGraph()\n",
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step we're going to take is to simply insert each of our full documents into the graph. This will provide a base that we can apply transformations to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 2, relationships: 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.graph import Node, NodeType\n",
    "\n",
    "for doc in docs:\n",
    "    kg.nodes.append(\n",
    "        Node(\n",
    "            type=NodeType.DOCUMENT,\n",
    "            properties={\"page_content\": doc.page_content, \"document_metadata\": doc.metadata}\n",
    "        )\n",
    "    )\n",
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll apply the *default* transformations to our knowledge graph. This will take the nodes currently on the graph and transform them based on a set of [default transformations](https://docs.ragas.io/en/latest/references/transforms/#ragas.testset.transforms.default_transforms).\n",
    "\n",
    "These default transformations are dependent on the corpus length, in our case:\n",
    "\n",
    "- Producing Summaries -> produces summaries of the documents\n",
    "- Extracting Headlines -> finding the overall headline for the document\n",
    "- Theme Extractor -> extracts broad themes about the documents\n",
    "\n",
    "It then uses cosine-similarity and heuristics between the embeddings of the above transformations to construct relationships between the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97509c4fc17641188bcdeb1f44377719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e1c2ac7f5fc4423bf12d9eb9eb7c79c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66e2229916b4af2afc21ba230840e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b54405b3c041d19c093f61a4714842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb8bd2b896f4894bc5ca68b327d5151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce360434385845a69ac9445cf3edac09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 10, relationships: 20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.transforms import default_transforms, apply_transforms\n",
    "\n",
    "transformer_llm = generator_llm\n",
    "embedding_model = generator_embeddings\n",
    "\n",
    "default_transforms = default_transforms(documents=docs, llm=transformer_llm, embedding_model=embedding_model)\n",
    "apply_transforms(kg, default_transforms)\n",
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save and load our knowledge graphs as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 10, relationships: 20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg.save(\"usecase_data_kg.json\")\n",
    "usecase_data_kg = KnowledgeGraph.load(\"usecase_data_kg.json\")\n",
    "usecase_data_kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our knowledge graph, we can construct a \"test set generator\" - which will allow us to create queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=embedding_model, knowledge_graph=usecase_data_kg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we'd like to be able to define the kinds of queries we're generating - which is made simple by Ragas having pre-created a number of different \"QuerySynthesizer\"s.\n",
    "\n",
    "Each of these Synthetsizers is going to tackle a separate kind of query which will be generated from a scenario and a persona.\n",
    "\n",
    "In essence, Ragas will use an LLM to generate a persona of someone who would interact with the data - and then use a scenario to construct a question from that data and persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers import default_query_distribution, SingleHopSpecificQuerySynthesizer, MultiHopAbstractQuerySynthesizer, MultiHopSpecificQuerySynthesizer\n",
    "\n",
    "query_distribution = [\n",
    "        (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 0.5),\n",
    "        (MultiHopAbstractQuerySynthesizer(llm=generator_llm), 0.25),\n",
    "        (MultiHopSpecificQuerySynthesizer(llm=generator_llm), 0.25),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùì Question #1:\n",
    "\n",
    "What are the three types of query synthesizers doing? Describe each one in simple terms.\n",
    "\n",
    "##### Answer:\n",
    "Ragas gives us three types of query synthesizers to generate different kinds of test questions, and each one tests our RAG system in a different way:\n",
    "\n",
    "- SingleHopSpecificQuerySynthesizer ‚Äî Creates straightforward, focused questions that can be answered from a single chunk of text. Think of it like a simple lookup ‚Äî \"What does Chapter 20 cover?\" or \"What is DBT?\" It only needs to find one relevant piece of context to answer. This is the easiest type of query for a RAG system to handle.\n",
    "- MultiHopAbstractQuerySynthesizer ‚Äî This one is more complex. It generates questions that require information from multiple chunks, but the question itself is more high-level and abstract. For example, \"How does sleep hygiene influence overall mental well-being?\" ‚Äî to answer this, the system needs to pull context from different parts of the documents and synthesize a broader, more conceptual answer.\n",
    "- MultiHopSpecificQuerySynthesizer ‚Äî This is similar to multi-hop abstract, in that it also needs multiple pieces of context, but the question is more specific and detailed. Something like \"How do Chapters 9 and 21 together inform strategies for stress management?\" ‚Äî it's asking for precise, concrete connections between specific sections. This is probably the hardest type for a RAG pipeline to get right because it needs both accurate retrieval across documents and specific, detailed reasoning.\n",
    "\n",
    "In the notebook, they're distributed as 50% single-hop specific, 25% multi-hop abstract, and 25% multi-hop specific, which makes sense because we want the bulk of tests to cover the basics, but also to stress-test with harder, multi-context questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use our `TestSetGenerator` to generate our testset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c29b29fba44091acc958592d95768c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1883ca074bce43e98601b98b4fe050cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c5240e8d9a403193112c355d831398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In United States mental health stuff how do pe...</td>\n",
       "      <td>[The Mental Health and Psychology Handbook A P...</td>\n",
       "      <td>The context explains that mental health in the...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is depression according to the context?</td>\n",
       "      <td>[PART 2: THERAPEUTIC APPROACHES Chapter 4: Cog...</td>\n",
       "      <td>The provided context does not include a specif...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does Vitamin D influence mental health?</td>\n",
       "      <td>[Write letters to or from your future self Jou...</td>\n",
       "      <td>Vitamin D is obtained from sunlight and fortif...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can I improve my mental health despite the...</td>\n",
       "      <td>[social interactions How to set and maintain b...</td>\n",
       "      <td>The digital age presents unique challenges for...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What role do vitamins play in maintaining ment...</td>\n",
       "      <td>[The Personal Wellness Guide A Comprehensive R...</td>\n",
       "      <td>The provided context does not include specific...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How does exercise influence the impact of ment...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nThe Mental Health and Psychology H...</td>\n",
       "      <td>The context explains that physical activity, s...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How does sleep hygeine and sleep quality impac...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nWrite letters to or from your futu...</td>\n",
       "      <td>The context explains that sleep and mental hea...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How do stress reduction techniques like mindfu...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 2: THERAPEUTIC APPROACHES Cha...</td>\n",
       "      <td>Stress reduction techniques such as mindfulnes...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How does sleep influence mental health, and wh...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nWrite letters to or from your futu...</td>\n",
       "      <td>Sleep has a significant impact on mental healt...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>how can CBT and CBT-I help with mental health ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 2: THERAPEUTIC APPROACHES Cha...</td>\n",
       "      <td>Cognitive Behavioral Therapy (CBT) is an effec...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How does vitamin D, as a key vitamin, influenc...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nThe Personal Wellness Guide A Comp...</td>\n",
       "      <td>Vitamin D, a vital micronutrient obtained from...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   In United States mental health stuff how do pe...   \n",
       "1        What is depression according to the context?   \n",
       "2         How does Vitamin D influence mental health?   \n",
       "3   How can I improve my mental health despite the...   \n",
       "4   What role do vitamins play in maintaining ment...   \n",
       "5   How does exercise influence the impact of ment...   \n",
       "6   How does sleep hygeine and sleep quality impac...   \n",
       "7   How do stress reduction techniques like mindfu...   \n",
       "8   How does sleep influence mental health, and wh...   \n",
       "9   how can CBT and CBT-I help with mental health ...   \n",
       "10  How does vitamin D, as a key vitamin, influenc...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [The Mental Health and Psychology Handbook A P...   \n",
       "1   [PART 2: THERAPEUTIC APPROACHES Chapter 4: Cog...   \n",
       "2   [Write letters to or from your future self Jou...   \n",
       "3   [social interactions How to set and maintain b...   \n",
       "4   [The Personal Wellness Guide A Comprehensive R...   \n",
       "5   [<1-hop>\\n\\nThe Mental Health and Psychology H...   \n",
       "6   [<1-hop>\\n\\nWrite letters to or from your futu...   \n",
       "7   [<1-hop>\\n\\nPART 2: THERAPEUTIC APPROACHES Cha...   \n",
       "8   [<1-hop>\\n\\nWrite letters to or from your futu...   \n",
       "9   [<1-hop>\\n\\nPART 2: THERAPEUTIC APPROACHES Cha...   \n",
       "10  [<1-hop>\\n\\nThe Personal Wellness Guide A Comp...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   The context explains that mental health in the...   \n",
       "1   The provided context does not include a specif...   \n",
       "2   Vitamin D is obtained from sunlight and fortif...   \n",
       "3   The digital age presents unique challenges for...   \n",
       "4   The provided context does not include specific...   \n",
       "5   The context explains that physical activity, s...   \n",
       "6   The context explains that sleep and mental hea...   \n",
       "7   Stress reduction techniques such as mindfulnes...   \n",
       "8   Sleep has a significant impact on mental healt...   \n",
       "9   Cognitive Behavioral Therapy (CBT) is an effec...   \n",
       "10  Vitamin D, a vital micronutrient obtained from...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   single_hop_specifc_query_synthesizer  \n",
       "5   multi_hop_abstract_query_synthesizer  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_specific_query_synthesizer  \n",
       "9   multi_hop_specific_query_synthesizer  \n",
       "10  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = generator.generate(testset_size=10, query_distribution=query_distribution)\n",
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstracted SDG\n",
    "\n",
    "The above method is the full process - but we can shortcut that using the provided abstractions!\n",
    "\n",
    "This will generate our knowledge graph under the hood, and will - from there - generate our personas and scenarios to construct our queries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99182961bb324a4e80fa5e11603f59e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2ccc90bfdc40e28b0e6074842f5854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e7b7d55da3943c3b1624b2d0c6714ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8cdac198344af88ea7ad097da9c83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c7bbf447a4451a948109698728e74f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ceb505206d248d88ef07cb4466fa6e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1a7ea84f4b4adf95e6e690008da3b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04622b80db394b4381e2bbd7d9f1c34c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9deb8f8c59504971879476344e3b5065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "dataset = generator.generate_with_langchain_docs(docs, testset_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the recommended exercises and strateg...</td>\n",
       "      <td>[The Personal Wellness Guide A Comprehensive R...</td>\n",
       "      <td>The provided context does not include specific...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What does Stage 2 of sleep involve in the slee...</td>\n",
       "      <td>[PART 3: SLEEP AND RECOVERY Chapter 7: The Sci...</td>\n",
       "      <td>Stage 2 involves a drop in body temperature an...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What information does Chapter 18 cover regardi...</td>\n",
       "      <td>[PART 5: BUILDING HEALTHY HABITS Chapter 13: T...</td>\n",
       "      <td>Chapter 18 discusses strategies to boost immun...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does the World Health Organization define ...</td>\n",
       "      <td>[The Mental Health and Psychology Handbook A P...</td>\n",
       "      <td>According to the World Health Organization, me...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how can exercise for common problems like lowe...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nThe Personal Wellness Guide A Comp...</td>\n",
       "      <td>The wellness guide explains that gentle exerci...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How can incorporating mindfulness and social c...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nhour before bed - No caffeine afte...</td>\n",
       "      <td>Incorporating mindfulness and social connectio...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How can improving face-to-face interactions an...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nhour before bed - No caffeine afte...</td>\n",
       "      <td>Improving face-to-face interactions by engagin...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How can I improve my emotional intelligence an...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nhour before bed - No caffeine afte...</td>\n",
       "      <td>To improve emotional intelligence and manage c...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>how chapter 7 and 17 connect about sleep and h...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 3: SLEEP AND RECOVERY Chapter...</td>\n",
       "      <td>chapter 7 talks about sleep and recovery, expl...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>H0w c4n I bUild a he4lthy m0rn1ng r0utine (cha...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 3: SLEEP AND RECOVERY Chapter...</td>\n",
       "      <td>To build a healthy morning routine that improv...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How can Cognitive Behavioral Therapy (CBT), in...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 3: SLEEP AND RECOVERY Chapter...</td>\n",
       "      <td>Cognitive Behavioral Therapy (CBT), particular...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How does Cognitive Behavioral Therapy (CBT) fo...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 3: SLEEP AND RECOVERY Chapter...</td>\n",
       "      <td>Cognitive Behavioral Therapy for Insomnia (CBT...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   What are the recommended exercises and strateg...   \n",
       "1   What does Stage 2 of sleep involve in the slee...   \n",
       "2   What information does Chapter 18 cover regardi...   \n",
       "3   How does the World Health Organization define ...   \n",
       "4   how can exercise for common problems like lowe...   \n",
       "5   How can incorporating mindfulness and social c...   \n",
       "6   How can improving face-to-face interactions an...   \n",
       "7   How can I improve my emotional intelligence an...   \n",
       "8   how chapter 7 and 17 connect about sleep and h...   \n",
       "9   H0w c4n I bUild a he4lthy m0rn1ng r0utine (cha...   \n",
       "10  How can Cognitive Behavioral Therapy (CBT), in...   \n",
       "11  How does Cognitive Behavioral Therapy (CBT) fo...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [The Personal Wellness Guide A Comprehensive R...   \n",
       "1   [PART 3: SLEEP AND RECOVERY Chapter 7: The Sci...   \n",
       "2   [PART 5: BUILDING HEALTHY HABITS Chapter 13: T...   \n",
       "3   [The Mental Health and Psychology Handbook A P...   \n",
       "4   [<1-hop>\\n\\nThe Personal Wellness Guide A Comp...   \n",
       "5   [<1-hop>\\n\\nhour before bed - No caffeine afte...   \n",
       "6   [<1-hop>\\n\\nhour before bed - No caffeine afte...   \n",
       "7   [<1-hop>\\n\\nhour before bed - No caffeine afte...   \n",
       "8   [<1-hop>\\n\\nPART 3: SLEEP AND RECOVERY Chapter...   \n",
       "9   [<1-hop>\\n\\nPART 3: SLEEP AND RECOVERY Chapter...   \n",
       "10  [<1-hop>\\n\\nPART 3: SLEEP AND RECOVERY Chapter...   \n",
       "11  [<1-hop>\\n\\nPART 3: SLEEP AND RECOVERY Chapter...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   The provided context does not include specific...   \n",
       "1   Stage 2 involves a drop in body temperature an...   \n",
       "2   Chapter 18 discusses strategies to boost immun...   \n",
       "3   According to the World Health Organization, me...   \n",
       "4   The wellness guide explains that gentle exerci...   \n",
       "5   Incorporating mindfulness and social connectio...   \n",
       "6   Improving face-to-face interactions by engagin...   \n",
       "7   To improve emotional intelligence and manage c...   \n",
       "8   chapter 7 talks about sleep and recovery, expl...   \n",
       "9   To build a healthy morning routine that improv...   \n",
       "10  Cognitive Behavioral Therapy (CBT), particular...   \n",
       "11  Cognitive Behavioral Therapy for Insomnia (CBT...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   multi_hop_abstract_query_synthesizer  \n",
       "5   multi_hop_abstract_query_synthesizer  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_specific_query_synthesizer  \n",
       "9   multi_hop_specific_query_synthesizer  \n",
       "10  multi_hop_specific_query_synthesizer  \n",
       "11  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùì Question #2:\n",
    "\n",
    "Ragas offers both an \"unrolled\" (manual) approach and an \"abstracted\" (automatic) approach to synthetic data generation. What are the trade-offs between these two approaches? When would you choose one over the other?\n",
    "\n",
    "##### Answer:\n",
    "From working through the notebook, here's what I noticed about the two approaches:\n",
    "\n",
    "1. Unrolled (Manual) Approach:\n",
    "- We build everything step by step ‚Äî create the knowledge graph, apply transformations manually, define our own query distribution with specific synthesizers and weights, and then generate the test set.\n",
    "- The big advantage is control. We get to decide exactly how the knowledge graph is built, we can save/load it separately, inspect it, and fine-tune the mix of query types (like we did with 50% single-hop, 25% multi-hop abstract, 25% multi-hop specific).\n",
    "- The downside is it's more code and more complexity and we need to understand how each piece fits together.\n",
    "\n",
    "2. Abstracted (Automatic) Approach:\n",
    "\n",
    "- It's basically a one-liner ‚Äî generator.generate_with_langchain_docs(docs, testset_size=10). Ragas handles the knowledge graph creation, transformations, and query distribution under the hood.\n",
    "- The advantage is simplicity and speed. We can get a test set generated really quickly without worrying about the internals.\n",
    "- The trade-off is you lose fine-grained control over things like query type distribution, which transformations get applied, or the ability to reuse the knowledge graph.\n",
    "\n",
    "When I'd choose each:\n",
    "\n",
    "I'd go with the abstracted approach for quick prototyping or when I just need a basic evaluation dataset fast ‚Äî like early in development when I'm iterating quickly and just want a sanity check on my RAG pipeline.\n",
    "I'd switch to the unrolled approach when I need more rigorous, repeatable evaluation ‚Äî for example, when I want to control the difficulty mix of questions, reuse the same knowledge graph across experiments for consistency, or when I'm doing a final evaluation before deploying to production. Being able to save and reload the knowledge graph is really useful for reproducibility.\n",
    "Basically, the abstracted version is great for getting started, but as the evaluation needs mature, the unrolled version gives the flexibility that we eventually need.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üèóÔ∏è Activity #1: Custom Query Distribution\n",
    "\n",
    "Modify the `query_distribution` to experiment with different ratios of query types.\n",
    "\n",
    "### Requirements:\n",
    "1. Create a custom query distribution with different weights than the default\n",
    "2. Generate a new test set using your custom distribution\n",
    "3. Compare the types of questions generated with the default distribution\n",
    "4. Explain why you chose the weights you did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "832d3c9c8d544da49f0f66671686efcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e336a94d0dc8438986f58056b84d453d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DEFAULT Distribution Results ===\n",
      "synthesizer_name\n",
      "single_hop_specifc_query_synthesizer    5\n",
      "multi_hop_abstract_query_synthesizer    3\n",
      "multi_hop_specific_query_synthesizer    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== CUSTOM Distribution Results ===\n",
      "synthesizer_name\n",
      "multi_hop_abstract_query_synthesizer    4\n",
      "multi_hop_specific_query_synthesizer    4\n",
      "single_hop_specifc_query_synthesizer    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Sample Questions Comparison ===\n",
      "\n",
      "--- single_hop_specifc_query_synthesizer ---\n",
      "  ‚Ä¢ What does the World Health Organization define as mental health?...\n",
      "  ‚Ä¢ What is MBSR and how does it contribute to stress reduction and well-being?...\n",
      "\n",
      "--- multi_hop_abstract_query_synthesizer ---\n",
      "  ‚Ä¢ mental health and well being how social emotional health connect...\n",
      "  ‚Ä¢ How does face-to-face interactions role in social support and mental health?...\n",
      "\n",
      "--- multi_hop_specific_query_synthesizer ---\n",
      "  ‚Ä¢ how exercise helps mental health and why doing exercise is good for your mental health like in the c...\n",
      "  ‚Ä¢ How does regular exercise, as discussed in both the first and second parts of the context, contribut...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# I'm shifting the weights towards multi-hop queries (75% multi-hop vs 25% single-hop).\n",
    "custom_query_distribution = [\n",
    "    (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 0.25),\n",
    "    (MultiHopAbstractQuerySynthesizer(llm=generator_llm), 0.40),\n",
    "    (MultiHopSpecificQuerySynthesizer(llm=generator_llm), 0.35),\n",
    "]\n",
    "\n",
    "# Generate test set with custom distribution\n",
    "custom_testset = generator.generate(testset_size=10, query_distribution=custom_query_distribution)\n",
    "custom_df = custom_testset.to_pandas()\n",
    "\n",
    "# Compare with the default distribution\n",
    "default_df = testset.to_pandas()\n",
    "\n",
    "print(\"=== DEFAULT Distribution Results ===\")\n",
    "print(default_df[\"synthesizer_name\"].value_counts())\n",
    "print()\n",
    "print(\"=== CUSTOM Distribution Results ===\")\n",
    "print(custom_df[\"synthesizer_name\"].value_counts())\n",
    "print()\n",
    "\n",
    "# Side-by-side comparison\n",
    "print(\"=== Sample Questions Comparison ===\")\n",
    "for synth_name in custom_df[\"synthesizer_name\"].unique():\n",
    "    print(f\"\\n--- {synth_name} ---\")\n",
    "    samples = custom_df[custom_df[\"synthesizer_name\"] == synth_name][\"user_input\"].head(2)\n",
    "    for q in samples:\n",
    "        print(f\"  ‚Ä¢ {q[:100]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Here's a comparison of the two distributions based on the results:\n",
    "\n",
    "Quality Differences in the Generated Questions:\n",
    "\n",
    "- Single-hop questions are clean and direct ‚Äî \"What does the WHO define as mental health?\" ‚Äî basically factoid retrieval from one chunk. Easy for a RAG pipeline.\n",
    "- Multi-hop abstract questions are noticeably fuzzier and more conversational ‚Äî \"mental health and well being how social emotional health connect\". They read almost like how a real user would type a search query. These test whether our retrieval can handle vague, broad queries that span multiple sections.\n",
    "- Multi-hop specific questions are the most complex ‚Äî \"How does regular exercise, as discussed in both the first and second parts of the context, contribute to...\". They explicitly reference multiple sections and demand precise cross-document reasoning. These are the hardest for a RAG system.\n",
    "\n",
    "Key Takeaway: \n",
    "\n",
    "By shifting from 50/25/25 to 25/40/35, we went from a majority of easy lookups to a majority of harder multi-hop questions. This means our custom test set is a tougher evaluation benchmark ‚Äî if the RAG pipeline scores well on this distribution, we can be more confident it handles real-world complex queries, not just simple fact retrieval. The trade-off is that absolute scores will likely be lower, but that's fine because RAGAS is best used for directional comparison anyway (as the notebook itself mentioned).\n",
    "\n",
    "4. Why these weights? \n",
    "\n",
    "I went heavier on multi-hop queries (40% abstract + 35% specific = 75% multi-hop) because the original distribution was dominated by simple single-hop lookups. In a real health & wellness app, users ask questions that cross topics ‚Äî like connecting sleep habits to stress management or nutrition to mental health. By stress-testing with more multi-hop queries, we can catch retrieval failures where the system struggles to pull relevant context from multiple documents. The 40/35 split between abstract and specific multi-hop ensures we test both high-level synthesis and precise cross-reference capabilities.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vSRr2MXk0P_"
   },
   "source": [
    "We'll need to provide our LangSmith API key, and set tracing to \"true\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLDUsLJg43k7"
   },
   "source": [
    "---\n",
    "# ü§ù Breakout Room #2\n",
    "## RAG Evaluation with LangSmith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SLtk1GtnyoY"
   },
   "source": [
    "## Task 4: LangSmith Dataset\n",
    "\n",
    "Now we can move on to creating a dataset for LangSmith!\n",
    "\n",
    "First, we'll need to create a dataset on LangSmith using the `Client`!\n",
    "\n",
    "We'll name our Dataset to make it easy to work with later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "TLgm6OjvYSsm"
   },
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "import uuid\n",
    "\n",
    "client = Client()\n",
    "\n",
    "dataset_name = f\"Use Case Synthetic Data - AIE9 - {uuid.uuid4()}\"\n",
    "\n",
    "langsmith_dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Synthetic Data for Use Cases\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64SmXMBnzXWm"
   },
   "source": [
    "We'll iterate through the RAGAS created dataframe - and add each example to our created dataset!\n",
    "\n",
    "> NOTE: We need to conform the outputs to the expected format - which in this case is: `question` and `answer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "8nFQ6di_XnY7"
   },
   "outputs": [],
   "source": [
    "for data_row in dataset.to_pandas().iterrows():\n",
    "  client.create_example(\n",
    "      inputs={\n",
    "          \"question\": data_row[1][\"user_input\"]\n",
    "      },\n",
    "      outputs={\n",
    "          \"answer\": data_row[1][\"reference\"]\n",
    "      },\n",
    "      metadata={\n",
    "          \"context\": data_row[1][\"reference_contexts\"]\n",
    "      },\n",
    "      dataset_id=langsmith_dataset.id\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6EbQVyZq-2j"
   },
   "source": [
    "## Basic RAG Chain\n",
    "\n",
    "Time for some RAG!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4njbUAIsaYjB"
   },
   "outputs": [],
   "source": [
    "rag_documents = docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQorBy8H1AZR"
   },
   "source": [
    "To keep things simple, we'll just use LangChain's recursive character text splitter!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "qWo3Ajaragv1"
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "rag_documents = text_splitter.split_documents(rag_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kghuTb9R01oO"
   },
   "source": [
    "We'll create our vectorstore using OpenAI's [`text-embedding-3-small`](https://platform.openai.com/docs/guides/embeddings/embedding-models) embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "UwfJCzP3aqKI"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QpCLS-a01Ft2"
   },
   "source": [
    "As usual, we will power our RAG application with Qdrant!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "58Ypj_NgbEsi"
   },
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "\n",
    "vectorstore = QdrantVectorStore.from_documents(\n",
    "    documents=rag_documents,\n",
    "    embedding=embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"use_case_rag\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "SbKSjfSkbTYo"
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxUOMaQX1K2N"
   },
   "source": [
    "To get the \"A\" in RAG, we'll provide a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "1sLeY1oWbVqO"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "RAG_PROMPT = \"\"\"\\\n",
    "Given a provided context and question, you must answer the question based only on context.\n",
    "\n",
    "If you cannot answer the question based on the context - you must say \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZnHDh4e1Ou5"
   },
   "source": [
    "As is usual: We'll be using `gpt-4.1-mini` for our RAG!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "6nx-ue1XbciV"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmTL6-pc1ZGz"
   },
   "source": [
    "Finally, we can set-up our RAG LCEL chain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "TjWj0OLIbbFc"
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "    | rag_prompt | llm | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "WQ7bEweo4IIb",
    "outputId": "d161b269-f799-4920-d6ce-c202f6e783aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Recommended exercises for lower back pain include:\\n\\n- Cat-Cow Stretch: Start on hands and knees, alternate between arching your back up (cat) and letting it sag down (cow). Do 10-15 repetitions.\\n- Bird Dog: From hands and knees, extend opposite arm and leg while keeping your core engaged. Hold for 5 seconds, then switch sides. Do 10 repetitions per side.\\n- Partial Crunches: Lie on your back with knees bent, cross arms over chest, tighten stomach muscles and raise shoulders off floor. Hold briefly, then lower. Do 8-12 repetitions.\\n- Knee-to-Chest Stretch: Lie on your back, pull one knee toward your chest while keeping the other foot flat. Hold for 15-30 seconds, then switch legs.\\n- Pelvic Tilts: Lie on your back with knees bent, flatten your back against the floor by tightening abs and tilting pelvis up slightly. Hold for 10 seconds, repeat 8-12 times.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"question\" : \"What are some recommended exercises for lower back pain?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9hBh5YPrdGJ"
   },
   "source": [
    "## LangSmith Evaluation Set-up\n",
    "\n",
    "We'll use OpenAI's GPT-4.1 as our evaluation LLM for our base Evaluators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "gfwPYdIkcvpF"
   },
   "outputs": [],
   "source": [
    "eval_llm = ChatOpenAI(model=\"gpt-4.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6b8pToKH2K28"
   },
   "source": [
    "We'll be using a number of evaluators - from LangSmith provided evaluators, to a few custom evaluators!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "PXSG-_ajckp6"
   },
   "outputs": [],
   "source": [
    "from openevals.llm import create_llm_as_judge\n",
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# 1. QA Correctness (replaces LangChainStringEvaluator(\"qa\"))\n",
    "qa_evaluator = create_llm_as_judge(\n",
    "    prompt=\"You are evaluating a QA system. Given the input, assess whether the prediction is correct.\\n\\nInput: {inputs}\\nPrediction: {outputs}\\nReference answer: {reference_outputs}\\n\\nIs the prediction correct? Return 1 if correct, 0 if incorrect.\",\n",
    "    feedback_key=\"qa\",\n",
    "    model=\"openai:gpt-4o\" ,  # pass your LangChain chat model directly\n",
    ")\n",
    "\n",
    "# 2. Labeled Helpfulness (replaces LangChainStringEvaluator(\"labeled_criteria\"))\n",
    "labeled_helpfulness_evaluator = create_llm_as_judge(\n",
    "    prompt=(\n",
    "        \"You are assessing a submission based on the following criterion:\\n\\n\"\n",
    "        \"helpfulness: Is this submission helpful to the user, \"\n",
    "        \"taking into account the correct reference answer?\\n\\n\"\n",
    "        \"Input: {inputs}\\n\"\n",
    "        \"Submission: {outputs}\\n\"\n",
    "        \"Reference answer: {reference_outputs}\\n\\n\"\n",
    "        \"Does the submission meet the criterion? Return 1 if yes, 0 if no.\"\n",
    "    ),\n",
    "    feedback_key=\"helpfulness\",\n",
    "    model=\"openai:gpt-4o\" ,\n",
    ")\n",
    "\n",
    "# 3. Dopeness (replaces LangChainStringEvaluator(\"criteria\"))\n",
    "dopeness_evaluator = create_llm_as_judge(\n",
    "    prompt=(\n",
    "        \"You are assessing a submission based on the following criterion:\\n\\n\"\n",
    "        \"dopeness: Is this response dope, lit, cool, or is it just a generic response?\\n\\n\"\n",
    "        \"Input: {inputs}\\n\"\n",
    "        \"Submission: {outputs}\\n\\n\"\n",
    "        \"Does the submission meet the criterion? Return 1 if yes, 0 if no.\"\n",
    "    ),\n",
    "    feedback_key=\"dopeness\",\n",
    "    model=\"openai:gpt-4o\" ,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0SQP_FoCetP"
   },
   "source": [
    "> **Describe what each evaluator is evaluating:**\n",
    ">\n",
    "> - `qa_evaluator`:\n",
    "> - `labeled_helpfulness_evaluator`:\n",
    "> - `dopeness_evaluator`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R35sQMHVrnpl"
   },
   "source": [
    "## LangSmith Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "122b1bd1f0e9417a8dcb57d4eebe4d2e",
      "e0c233ad01604540a6c873f4a731982d",
      "e9a01115c75b499884f7e0ef32e9e599",
      "5faba4ad609448b2b49024add4ad3b8e",
      "ef25efa751304e4699910f1fbc14345f",
      "0b44cb0f8e34446c8dde668a75d3d8ad",
      "edaac6587b2d4bd5be52b89bb097f99f",
      "7cb241365f604419af454c1c28de197a",
      "9cf586576ff44dba86ba2eb389593c61",
      "849b5c95008541d49f1ceedf0a59ac60",
      "f3665a86662746c4ac7cb0796604781d"
     ]
    },
    "id": "t7t_Uz0tdumL",
    "outputId": "d684e218-294e-4dc3-c8de-a01d397f021c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'essential-night-19' at:\n",
      "https://eu.smith.langchain.com/o/2fe1c7ad-0fb5-4a33-9b4b-3dd820425a13/datasets/22b30e93-13c7-4274-b32b-b0b61b98db44/compare?selectedSessions=347291a5-9638-48d9-88f7-dce9b71c7050\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92c0f65b571421a8b52696b87b07a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.qa</th>\n",
       "      <th>feedback.helpfulness</th>\n",
       "      <th>feedback.dopeness</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can exercise improve mental health and wha...</td>\n",
       "      <td>Exercise improves mental health through multip...</td>\n",
       "      <td>None</td>\n",
       "      <td>Exercise improves mental health by releasing e...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.906751</td>\n",
       "      <td>d3b4d1ec-a391-49d8-9e7b-8331a41e4d24</td>\n",
       "      <td>019c5322-81ce-7021-a7dc-14287b99b9e0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can incorporating regular exercise, as rec...</td>\n",
       "      <td>Incorporating regular exercise improves mental...</td>\n",
       "      <td>None</td>\n",
       "      <td>The provided context highlights that regular e...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3.818964</td>\n",
       "      <td>713e87c6-5e61-4f8c-a50e-51d6a1cdcce2</td>\n",
       "      <td>019c5322-be90-7873-b48c-2ae0d888172b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does CBT-I incorporate principles from CBT...</td>\n",
       "      <td>CBT-I (Cognitive Behavioral Therapy for Insomn...</td>\n",
       "      <td>None</td>\n",
       "      <td>CBT-I, or Cognitive Behavioral Therapy for Ins...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.926847</td>\n",
       "      <td>254649d3-3039-41ab-89e6-948f73e81106</td>\n",
       "      <td>019c5322-f4af-7851-9ead-5ce43d04c31c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does CBT-I relate to the use of CBT for me...</td>\n",
       "      <td>Based on the provided context:\\n\\nCBT-I (Cogni...</td>\n",
       "      <td>None</td>\n",
       "      <td>CBT-I, or Cognitive Behavioral Therapy for Ins...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4.711107</td>\n",
       "      <td>23a088e0-f471-4ecb-88eb-a743389ee12f</td>\n",
       "      <td>019c5323-26b0-7ad3-918d-b736d0533dd8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hw does gut-brain axis and probiotics affect m...</td>\n",
       "      <td>The gut-brain axis influences mental health th...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context explains that the gut-brain axis i...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.986962</td>\n",
       "      <td>6366b82b-0df3-4a7b-9258-50a9f76d03ee</td>\n",
       "      <td>019c5323-625d-7662-aa60-3b6fae6d6b16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How can I buid healthy habbits and improve my ...</td>\n",
       "      <td>To build healthy habits and improve your sleep...</td>\n",
       "      <td>None</td>\n",
       "      <td>To build healthy habits and enhance your sleep...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4.532756</td>\n",
       "      <td>a65d9dbc-a740-4c03-bbdc-be6789af558c</td>\n",
       "      <td>019c5323-ae2d-7e91-9bcc-04a14ac1bf44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How can managing common health concerns like h...</td>\n",
       "      <td>According to the provided context, managing co...</td>\n",
       "      <td>None</td>\n",
       "      <td>Managing common health concerns such as headac...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.685956</td>\n",
       "      <td>80b9d9f9-5fc0-49d2-ac61-1e8cb89246d7</td>\n",
       "      <td>019c5323-f84a-7c92-8641-4762fe987f70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How can incorporating mindfulness and meditati...</td>\n",
       "      <td>Incorporating mindfulness and meditation pract...</td>\n",
       "      <td>None</td>\n",
       "      <td>Incorporating mindfulness and meditation pract...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4.827632</td>\n",
       "      <td>8273ab46-8c47-4929-a204-ccee3b124bff</td>\n",
       "      <td>019c5324-336c-7432-9b4b-20b9a3d09a09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How do Psychologists help with setting and mai...</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>None</td>\n",
       "      <td>Psychologists are mental health professionals ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.426339</td>\n",
       "      <td>a1352ca2-fa66-4908-8dfc-0a937fa33b77</td>\n",
       "      <td>019c5324-7f1a-7022-b68f-3a726de011f2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How does exercise help improve mental health a...</td>\n",
       "      <td>Exercise helps improve mental health in severa...</td>\n",
       "      <td>None</td>\n",
       "      <td>Exercise affects the brain in multiple benefic...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3.726100</td>\n",
       "      <td>5d814f04-4c9c-4a35-b39b-5ceb1e141a4d</td>\n",
       "      <td>019c5324-a46a-7013-ad07-8bc9fecfd199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What is the University of Massachusetts Medica...</td>\n",
       "      <td>The University of Massachusetts Medical Center...</td>\n",
       "      <td>None</td>\n",
       "      <td>The University of Massachusetts Medical Center...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.738838</td>\n",
       "      <td>d7847b00-c210-4a81-bbbf-454441bfeb75</td>\n",
       "      <td>019c5324-e77e-7272-bfa8-e8fb9e378cd0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What does the World Health Organization say ab...</td>\n",
       "      <td>According to the World Health Organization, me...</td>\n",
       "      <td>None</td>\n",
       "      <td>According to the World Health Organization, me...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.402837</td>\n",
       "      <td>f77d28b3-393b-479d-b749-002aec9a948c</td>\n",
       "      <td>019c5325-1f48-7323-8928-c58fdf9f1719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults essential-night-19>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    rag_chain.invoke,\n",
    "    data=dataset_name,\n",
    "    evaluators=[\n",
    "        qa_evaluator,\n",
    "        labeled_helpfulness_evaluator,\n",
    "        dopeness_evaluator\n",
    "    ],\n",
    "    metadata={\"revision_id\": \"default_chain_init\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nq7fCVinrpI4"
   },
   "source": [
    "## Dope-ifying Our Application\n",
    "\n",
    "We'll be making a few changes to our RAG chain to increase its performance on our SDG evaluation test dataset!\n",
    "\n",
    "- Include a \"dope\" prompt augmentation\n",
    "- Use larger chunks\n",
    "- Improve the retriever model to: `text-embedding-3-large`\n",
    "\n",
    "Let's see how this changes our evaluation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "z56pXwyUgFUt"
   },
   "outputs": [],
   "source": [
    "DOPENESS_RAG_PROMPT = \"\"\"\\\n",
    "Given a provided context and question, you must answer the question based only on context.\n",
    "\n",
    "If you cannot answer the question based on the context - you must say \"I don't know\".\n",
    "\n",
    "Make your answer rad, ensure high levels of dopeness. Do not be generic, or give generic responses.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "dopeness_rag_prompt = ChatPromptTemplate.from_template(DOPENESS_RAG_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "rZLcTstJgfv5"
   },
   "outputs": [],
   "source": [
    "rag_documents = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "-LYsyirngj6n"
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "rag_documents = text_splitter.split_documents(rag_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spldiPuTCzDO"
   },
   "source": [
    "## ‚ùì Question #3:\n",
    "\n",
    "Why would modifying our chunk size modify the performance of our application?\n",
    "\n",
    "##### Answer:\n",
    "## ‚ùì Question #2:\n",
    "\n",
    "Ragas offers both an \"unrolled\" (manual) approach and an \"abstracted\" (automatic) approach to synthetic data generation. What are the trade-offs between these two approaches? When would you choose one over the other?\n",
    "\n",
    "##### Answer:\n",
    "Chunk size is basically how much text we pack into each piece before embedding it and storing it in the vector database. Changing it has a direct impact on retrieval quality, which cascades into the whole RAG pipeline:\n",
    "\n",
    "- Too small chunks (e.g., 200 characters) ‚Äî each chunk captures very little context. The embeddings become very narrow and specific. This means retrieval might find a relevant sentence but miss the surrounding explanation needed to actually answer the question. The LLM then gets fragmented context and may produce incomplete or incoherent answers.\n",
    "- Too large chunks (e.g., 5000 characters) ‚Äî each chunk contains a lot of information, but the embedding has to represent all of it in a single vector. This \"dilutes\" the semantic meaning ‚Äî the embedding becomes a blurry average of many topics. So when we search for something specific, a large chunk might not rank as highly because its embedding doesn't closely match the query. Plus, we'd be feeding a lot of irrelevant text to the LLM alongside the relevant bit, which wastes tokens and can confuse the model.\n",
    "- The sweet spot (like the 1000 we're using in the notebook with 50 overlap) tries to balance both ‚Äî enough context for a meaningful answer, but focused enough that the embedding accurately represents the content. The overlap of 50 helps ensure we don't accidentally cut a key idea right at a chunk boundary.\n",
    "\n",
    "So in short, chunk size affects what gets retrieved and how much useful context the LLM sees. It's one of the most impactful parameters in a RAG system, and that's exactly why evaluation tools like RAGAS and LangSmith matter ‚Äî they let us actually measure the effect of changing it rather than just guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "b9MI2Bm2go1r"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBbjG6cKC8BQ"
   },
   "source": [
    "## ‚ùì Question #4:\n",
    "\n",
    "Why would modifying our embedding model modify the performance of our application?\n",
    "\n",
    "##### Answer:\n",
    "The embedding model is what translates text (both our document chunks and the user's query) into numerical vectors. Swapping it out changes how meaning is represented, which directly impacts retrieval:\n",
    "\n",
    "- Different models capture semantics differently. The notebook uses text-embedding-3-large, which is one of OpenAI's most capable embedding models. A smaller or older model (like text-embedding-ada-002) might not capture nuanced relationships between concepts as well. For example, a stronger model might understand that \"insomnia\" and \"sleep hygiene\" are related even though the words are different, while a weaker model might miss that connection.\n",
    "- Embedding dimensionality matters. Larger models typically produce higher-dimensional vectors, which can represent more subtle distinctions between concepts. This means retrieval is more precise ‚Äî the right chunks rank higher for a given query. But it also means more storage and slightly slower similarity search.\n",
    "- Domain fit plays a role. Some embedding models are fine-tuned for specific domains (medical, legal, etc.). If our health & wellness documents use specialized terminology, a general-purpose embedding model might not represent those terms as effectively as one trained on similar content.\n",
    "- Query-document alignment. The same model must embed both the query and the documents. If we switch models, the entire vector store needs to be re-embedded ‚Äî we can't mix embeddings from different models because they live in completely different vector spaces.\n",
    "\n",
    "So basically, the embedding model determines how well the system understands what's similar to what. A better model means more relevant chunks get retrieved, which means the LLM gets better context, which means better final answers. That's why ‚Äî combined with chunk size from Q3 ‚Äî these two parameters are probably the most impactful knobs to tune in a RAG pipeline, and exactly why we use RAGAS metrics and LangSmith to measure the impact of changing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "hVUY25FKgxXx"
   },
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "\n",
    "vectorstore = QdrantVectorStore.from_documents(\n",
    "    documents=rag_documents,\n",
    "    embedding=embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"Use Case RAG Docs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Q4TOZNYIg2v1"
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqYGFrnKDB91"
   },
   "source": [
    "Setting up our new and improved DOPE RAG CHAIN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "HqnTqeXMhAdx"
   },
   "outputs": [],
   "source": [
    "dopeness_rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "    | dopeness_rag_prompt | llm | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21pTxoqJDI1Y"
   },
   "source": [
    "Let's test it on the same output that we saw before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "OfZZ3MoN3fKv",
    "outputId": "d65722dd-92c2-4e4e-9cca-c42ee6f3f208"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alright, let‚Äôs crank your sleep game to legendary status! Based on the epic wisdom packed in the context, here‚Äôs your dope roadmap to unlocking next-level sleep quality:\\n\\n1. **Consistency is KING** ‚Äî Hit the sack and rise up at the same time every. single. day. Weekends don‚Äôt get a free pass. Your circadian rhythm thrives on routine, so stick to it like a boss.\\n\\n2. **Craft a Chill Bedtime Ritual** ‚Äî Think reading your fave book, gentle stretching, or a warm bath that melts stress away. This signals your brain it‚Äôs chillax time.\\n\\n3. **Zen out your sleep zone** ‚Äî Keep your bedroom cool (65-68¬∞F/18-20¬∞C), dark (blackout curtains or sleep mask, no exceptions), and silent (white noise machines or earplugs will be your sleep ninjas). Invest in killer pillows and a mattress that cradles you like royalty.\\n\\n4. **Ditch the Screens Early** ‚Äî Power down devices 1-2 hours before lights out. The blue light beast messes with your melatonin, your natural sleep hormone.\\n\\n5. **Caffeine Cutoff Clock: 2 PM** ‚Äî No rocket fuel post-afternoon. Otherwise, you‚Äôll be counting sheep all night.\\n\\n6. **Move that Body, But Not Too Close to Bedtime** ‚Äî Regular exercise pumps your sleep quality up, but late-night sweat sessions can backfire.\\n\\n7. **Light on Alcohol & Heavy Noms at Night** ‚Äî These disrupt your sleep cycles, so keep it easy on the late bites and booze.\\n\\nLayering all these legendary moves will make your sleep quality shine like a cosmic supernova‚Äînot just more sleep, but deeper, more restorative cycles that have you waking sharp, energized, and ready to crush it. Sweet dreams, sleep warrior! üåô‚ú®'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dopeness_rag_chain.invoke({\"question\" : \"How can I improve my sleep quality?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpj7v1inDLnQ"
   },
   "source": [
    "Finally, we can evaluate the new chain on the same test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "bf8dcc0895054529af356da401c513f6",
      "7dce19ac55264f2b88a0e4730e55867b",
      "2a0755d4476543feb4a64538e3e37213",
      "158212a630f04cbd884c937f2f60f5c8",
      "11c7f66acc1d45be9517d0addf49331e",
      "ddffd834e09940a4bd3874c3f39b4e21",
      "ef63c3b2d51e452da03cdae5d9b034be",
      "c20b539cd70b4ba99601ad1d69fd9cec",
      "a6d681eeafa44d18b933a4c5dec88382",
      "d1d54ccd56494c4d831f71b416a1f880",
      "530f696feefe499da08c6312047379b2"
     ]
    },
    "id": "Dx11S2b-hIM8",
    "outputId": "d3a3ea78-aa32-4bd2-8c2a-d0d0303695c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'pertinent-society-64' at:\n",
      "https://eu.smith.langchain.com/o/2fe1c7ad-0fb5-4a33-9b4b-3dd820425a13/datasets/22b30e93-13c7-4274-b32b-b0b61b98db44/compare?selectedSessions=00ceb112-18a7-45b0-9196-9ac6cf4877c4\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be2207274ea84b3db595475baaec6d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.qa</th>\n",
       "      <th>feedback.helpfulness</th>\n",
       "      <th>feedback.dopeness</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can exercise improve mental health and wha...</td>\n",
       "      <td>Yo, strap in ‚Äî exercise isn‚Äôt just flexing mus...</td>\n",
       "      <td>None</td>\n",
       "      <td>Exercise improves mental health by releasing e...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.495559</td>\n",
       "      <td>d3b4d1ec-a391-49d8-9e7b-8331a41e4d24</td>\n",
       "      <td>019c5325-d182-77f0-abbe-2f05b86a4c9f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can incorporating regular exercise, as rec...</td>\n",
       "      <td>Yo, here‚Äôs the lowdown straight from the menta...</td>\n",
       "      <td>None</td>\n",
       "      <td>The provided context highlights that regular e...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4.922920</td>\n",
       "      <td>713e87c6-5e61-4f8c-a50e-51d6a1cdcce2</td>\n",
       "      <td>019c5326-30db-7591-a5b5-636e0807e94e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does CBT-I incorporate principles from CBT...</td>\n",
       "      <td>Yo, let‚Äôs break down how CBT-I legit channels ...</td>\n",
       "      <td>None</td>\n",
       "      <td>CBT-I, or Cognitive Behavioral Therapy for Ins...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>8.737433</td>\n",
       "      <td>254649d3-3039-41ab-89e6-948f73e81106</td>\n",
       "      <td>019c5326-780a-7b53-8c27-13f49984a653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does CBT-I relate to the use of CBT for me...</td>\n",
       "      <td>Yo, here‚Äôs the slick lowdown straight from the...</td>\n",
       "      <td>None</td>\n",
       "      <td>CBT-I, or Cognitive Behavioral Therapy for Ins...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4.687644</td>\n",
       "      <td>23a088e0-f471-4ecb-88eb-a743389ee12f</td>\n",
       "      <td>019c5326-cd88-70d1-9b33-405fde4625a9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hw does gut-brain axis and probiotics affect m...</td>\n",
       "      <td>Yo, here‚Äôs the straight-up cosmic connection b...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context explains that the gut-brain axis i...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4.453433</td>\n",
       "      <td>6366b82b-0df3-4a7b-9258-50a9f76d03ee</td>\n",
       "      <td>019c5327-1b3e-76e0-94f5-c580ea19eeaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How can I buid healthy habbits and improve my ...</td>\n",
       "      <td>Alright, let‚Äôs crank your wellness game to leg...</td>\n",
       "      <td>None</td>\n",
       "      <td>To build healthy habits and enhance your sleep...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5.581946</td>\n",
       "      <td>a65d9dbc-a740-4c03-bbdc-be6789af558c</td>\n",
       "      <td>019c5327-5181-7243-965e-671261455551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How can managing common health concerns like h...</td>\n",
       "      <td>Yo, listen up‚Äîrocking your wellness game means...</td>\n",
       "      <td>None</td>\n",
       "      <td>Managing common health concerns such as headac...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5.814851</td>\n",
       "      <td>80b9d9f9-5fc0-49d2-ac61-1e8cb89246d7</td>\n",
       "      <td>019c5327-94c9-7d43-9634-90b237aee85b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How can incorporating mindfulness and meditati...</td>\n",
       "      <td>Oh heck yes, let‚Äôs dive deep into the rad worl...</td>\n",
       "      <td>None</td>\n",
       "      <td>Incorporating mindfulness and meditation pract...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.554741</td>\n",
       "      <td>8273ab46-8c47-4929-a204-ccee3b124bff</td>\n",
       "      <td>019c5327-d97b-7481-ac8d-a9cc130be5c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How do Psychologists help with setting and mai...</td>\n",
       "      <td>Alright, let‚Äôs crank up the mental health mojo...</td>\n",
       "      <td>None</td>\n",
       "      <td>Psychologists are mental health professionals ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4.781982</td>\n",
       "      <td>a1352ca2-fa66-4908-8dfc-0a937fa33b77</td>\n",
       "      <td>019c5328-2242-76e2-8c6a-35c388c37048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How does exercise help improve mental health a...</td>\n",
       "      <td>Alright, let‚Äôs crank up the mental health mojo...</td>\n",
       "      <td>None</td>\n",
       "      <td>Exercise affects the brain in multiple benefic...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4.407238</td>\n",
       "      <td>5d814f04-4c9c-4a35-b39b-5ceb1e141a4d</td>\n",
       "      <td>019c5328-5f48-7883-a94b-db4e565f6d13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What is the University of Massachusetts Medica...</td>\n",
       "      <td>Alright, buckle up for some mental health nerd...</td>\n",
       "      <td>None</td>\n",
       "      <td>The University of Massachusetts Medical Center...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.573965</td>\n",
       "      <td>d7847b00-c210-4a81-bbbf-454441bfeb75</td>\n",
       "      <td>019c5328-a708-7352-a989-0907fa03c762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What does the World Health Organization say ab...</td>\n",
       "      <td>Alright, here‚Äôs the dopest rundown straight fr...</td>\n",
       "      <td>None</td>\n",
       "      <td>According to the World Health Organization, me...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4.090030</td>\n",
       "      <td>f77d28b3-393b-479d-b749-002aec9a948c</td>\n",
       "      <td>019c5328-deb5-7591-999d-0efb11c4cb8d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults pertinent-society-64>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    dopeness_rag_chain.invoke,\n",
    "    data=dataset_name,\n",
    "    evaluators=[\n",
    "        qa_evaluator,\n",
    "        labeled_helpfulness_evaluator,\n",
    "        dopeness_evaluator\n",
    "    ],\n",
    "    metadata={\"revision_id\": \"dopeness_rag_chain\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3C7migvlDPZT"
   },
   "source": [
    "---\n",
    "## üèóÔ∏è Activity #2: Analyze Evaluation Results\n",
    "\n",
    "Provide a screenshot of the difference between the two chains in LangSmith, and explain why you believe certain metrics changed in certain ways.\n",
    "\n",
    "##### Answer:\n",
    "![LangSmith comparison of the two chains](image.png)\n",
    "\n",
    "Looking at the LangSmith comparison between the two experiments, I can see clear patterns in how the metrics changed when switching from the baseline rag_chain to the dopeness_rag_chain:\n",
    "\n",
    "1. QA (Correctness) ‚Äî Stayed at ~1.00 for both chains. This makes sense because both chains use the exact same retriever and vector store, so they pull the same context documents. The only thing that changed was the prompt style, not the factual content of the answers. The LLM still extracts and presents the correct information ‚Äî it just wraps it in a different tone.\n",
    "\n",
    "2. Helpfulness ‚Äî Stayed at ~1.00 for both chains. Similar reasoning ‚Äî the underlying information and relevance of the answers didn't change. Whether the answer says \"maintain a consistent sleep schedule\" or \"hit the sack at the same time every day like a boss,\" the advice is equally helpful and covers the same ground as the reference answer.\n",
    "\n",
    "3. Dopeness ‚Äî Changed dramatically from 0.00 (baseline) to 1.00 (dopeness chain). This is the most significant change and it's entirely expected. The baseline chain uses a standard, professional prompt, so it naturally scores 0 on dopeness ‚Äî it was never designed to be \"dope.\" The dopeness chain explicitly instructs the LLM to respond with excitement, slang, and energy, which is exactly what the custom dopeness evaluator is looking for. This shows that custom evaluators can effectively measure specific behavioral changes in the output.\n",
    "\n",
    "4. Latency ‚Äî Slightly higher for the dopeness chain. The casual, energetic style tends to generate longer, more expressive responses (e.g., adding intros like \"Alright, let's crank up the mental health mojo!\" and emojis). More output tokens = more generation time.\n",
    "\n",
    "5. Total Tokens ‚Äî Higher for the dopeness chain. Directly related to latency ‚Äî the dopeness prompt encourages verbose, enthusiastic responses, so the output token count increases. The input tokens are roughly the same since the retrieved context is identical.\n",
    "\n",
    "Key takeaway: This comparison demonstrates that prompt engineering can dramatically change style-based metrics without affecting accuracy-based metrics, as long as the retrieval pipeline stays the same. It also shows the value of custom evaluators ‚Äî without the dopeness evaluator, we wouldn't have been able to quantify the stylistic difference between the two chains at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "In this session, we:\n",
    "\n",
    "1. **Generated synthetic test data** using Ragas' knowledge graph-based approach\n",
    "2. **Explored query synthesizers** for creating diverse question types\n",
    "3. **Loaded synthetic data** into a LangSmith dataset for evaluation\n",
    "4. **Built and evaluated a RAG chain** using LangSmith evaluators\n",
    "5. **Iterated on the pipeline** by modifying chunk size, embedding model, and prompt ‚Äî then measured the impact\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "- **Synthetic data generation** is critical for early iteration ‚Äî it provides high-quality signal without manually creating test data\n",
    "- **LangSmith evaluators** enable systematic comparison of pipeline versions\n",
    "- **Small changes matter** ‚Äî chunk size, embedding model, and prompt modifications can significantly affect evaluation scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07ab3dc0790241bbb85a7f488a42ef8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7710c7377cbc4c30b55b28b4bc99e88f",
       "IPY_MODEL_41bdd49fab5f4826959d0d50663ff539",
       "IPY_MODEL_60168d85131d4afc99d55d61ab954ee6"
      ],
      "layout": "IPY_MODEL_9edf898aeeab40dda9b9475395776521"
     }
    },
    "095f680d37a3430fb82d223615662db5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0b44cb0f8e34446c8dde668a75d3d8ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10df31709059484c99f102453d780473": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1160a44dc18e47b0890f70c40eaa7eb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "11c7f66acc1d45be9517d0addf49331e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "122b1bd1f0e9417a8dcb57d4eebe4d2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e0c233ad01604540a6c873f4a731982d",
       "IPY_MODEL_e9a01115c75b499884f7e0ef32e9e599",
       "IPY_MODEL_5faba4ad609448b2b49024add4ad3b8e"
      ],
      "layout": "IPY_MODEL_ef25efa751304e4699910f1fbc14345f"
     }
    },
    "158212a630f04cbd884c937f2f60f5c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1d54ccd56494c4d831f71b416a1f880",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_530f696feefe499da08c6312047379b2",
      "value": "‚Äá20/?‚Äá[01:43&lt;00:00,‚Äá‚Äá5.25s/it]"
     }
    },
    "23863bc37a8645029934b8c106622c51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2508d229935744cbb5fc340222e2d660": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a0755d4476543feb4a64538e3e37213": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c20b539cd70b4ba99601ad1d69fd9cec",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a6d681eeafa44d18b933a4c5dec88382",
      "value": 1
     }
    },
    "33f063017b7c4c7fa8cbafc89674350b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6864c81e2bcf459bbaf5acbb36bdfcbe",
       "IPY_MODEL_59d6e269eadf429a924f6f79bc8ba4ba",
       "IPY_MODEL_ca791fc471e34b9da2f9070fc1053c0f"
      ],
      "layout": "IPY_MODEL_8baf0ed3d0f743f294e07f2b5407e820"
     }
    },
    "3a8537e37fc14fd9b16ca0ceee4fede6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41bdd49fab5f4826959d0d50663ff539": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6eb8b2e3262c45248708a2082c366f0a",
      "max": 64,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_095f680d37a3430fb82d223615662db5",
      "value": 64
     }
    },
    "530f696feefe499da08c6312047379b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59d6e269eadf429a924f6f79bc8ba4ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_890e0dd7fa524ceca1e805cb6253ee71",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_61b52ff459214129b8f7e6d67b192b78",
      "value": 20
     }
    },
    "5ab5f08afa5841709aedb2f78a52a11c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5c2fda99d4204d85b1bf7ad354fd58d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5faba4ad609448b2b49024add4ad3b8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_849b5c95008541d49f1ceedf0a59ac60",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f3665a86662746c4ac7cb0796604781d",
      "value": "‚Äá20/?‚Äá[01:27&lt;00:00,‚Äá‚Äá6.45s/it]"
     }
    },
    "60168d85131d4afc99d55d61ab954ee6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a8537e37fc14fd9b16ca0ceee4fede6",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_1160a44dc18e47b0890f70c40eaa7eb0",
      "value": "‚Äá61/64‚Äá[00:02&lt;00:00,‚Äá23.36it/s]"
     }
    },
    "61b52ff459214129b8f7e6d67b192b78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6864c81e2bcf459bbaf5acbb36bdfcbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10df31709059484c99f102453d780473",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_2508d229935744cbb5fc340222e2d660",
      "value": "Generating:‚Äá100%"
     }
    },
    "6eb8b2e3262c45248708a2082c366f0a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7710c7377cbc4c30b55b28b4bc99e88f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c2fda99d4204d85b1bf7ad354fd58d4",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_93cd4d35c5fd41f5904ca1d52d1f52a8",
      "value": "embedding‚Äánodes:‚Äá‚Äá95%"
     }
    },
    "7cb241365f604419af454c1c28de197a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "7dce19ac55264f2b88a0e4730e55867b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ddffd834e09940a4bd3874c3f39b4e21",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ef63c3b2d51e452da03cdae5d9b034be",
      "value": ""
     }
    },
    "849b5c95008541d49f1ceedf0a59ac60": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "890e0dd7fa524ceca1e805cb6253ee71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8baf0ed3d0f743f294e07f2b5407e820": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93cd4d35c5fd41f5904ca1d52d1f52a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9cf586576ff44dba86ba2eb389593c61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9edf898aeeab40dda9b9475395776521": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "a6d681eeafa44d18b933a4c5dec88382": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bf8dcc0895054529af356da401c513f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7dce19ac55264f2b88a0e4730e55867b",
       "IPY_MODEL_2a0755d4476543feb4a64538e3e37213",
       "IPY_MODEL_158212a630f04cbd884c937f2f60f5c8"
      ],
      "layout": "IPY_MODEL_11c7f66acc1d45be9517d0addf49331e"
     }
    },
    "c20b539cd70b4ba99601ad1d69fd9cec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "ca791fc471e34b9da2f9070fc1053c0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23863bc37a8645029934b8c106622c51",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_5ab5f08afa5841709aedb2f78a52a11c",
      "value": "‚Äá20/20‚Äá[00:52&lt;00:00,‚Äá‚Äá4.50s/it]"
     }
    },
    "d1d54ccd56494c4d831f71b416a1f880": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddffd834e09940a4bd3874c3f39b4e21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0c233ad01604540a6c873f4a731982d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b44cb0f8e34446c8dde668a75d3d8ad",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_edaac6587b2d4bd5be52b89bb097f99f",
      "value": ""
     }
    },
    "e9a01115c75b499884f7e0ef32e9e599": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7cb241365f604419af454c1c28de197a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9cf586576ff44dba86ba2eb389593c61",
      "value": 1
     }
    },
    "edaac6587b2d4bd5be52b89bb097f99f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef25efa751304e4699910f1fbc14345f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef63c3b2d51e452da03cdae5d9b034be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f3665a86662746c4ac7cb0796604781d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "state": {}
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
